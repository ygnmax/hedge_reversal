{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac842285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "from pandas.tseries.offsets import BDay\n",
    "import os\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d85dbb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if getpass.getuser() in ['ygnmax']:\n",
    "    if sys.platform == 'linux':\n",
    "        workdir = '/home/ygnmax/Dropbox/research_nyu/hedge_vol/'\n",
    "    if sys.platform == 'win32':\n",
    "        workdir = 'C:/Users/ygnmax/Dropbox (Personal)/research_nyu/hedge_vol/'\n",
    "os.chdir(workdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22cbbaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "# 1. Get stock list / dictionary\n",
    "#################################\n",
    "# read dot-com bubble companies\n",
    "df_dotcom = pd.read_excel(workdir + \"data/dot_com_firms.xlsx\", engine = 'openpyxl').dropna()\n",
    "df_dotcom[\"SecurityID\"] = df_dotcom[\"SecurityID\"].astype(int)\n",
    "\n",
    "# read big companies\n",
    "df_big = pd.read_excel(workdir + \"data/big_firms.xlsx\", engine = 'openpyxl').dropna()\n",
    "df_big[\"SecurityID\"] = df_big[\"SecurityID\"].astype(int)\n",
    "\n",
    "# read other companies\n",
    "df_other = pd.read_excel(workdir + \"data/other_firms.xlsx\").dropna()\n",
    "df_other[\"SecurityID\"] = df_other[\"SecurityID\"].astype(int)\n",
    "\n",
    "# append them together\n",
    "df_stock_list = pd.concat([df_dotcom[['Name','Ticker','SecurityID', 'Internet']], \n",
    "                           df_big[['Name','Ticker','SecurityID', 'Internet']], \n",
    "                          df_other[['Name','Ticker','SecurityID', 'Internet']]])\n",
    "# df_stock_list = pd.concat([df_stock_list, df_other[['Name','Ticker','SecurityID', 'Internet']]])\n",
    "df_stock_list[\"Internet\"] = df_stock_list[\"Internet\"].astype(int)\n",
    "df_stock_list = df_stock_list.dropna()\n",
    "df_stock_list = df_stock_list.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eae3459d-205c-4f4b-a81c-909d5f30068b",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = workdir + 'data/raw/WRDS_2021/' \n",
    "\n",
    "# read and clean zero curve\n",
    "zero_curve = pd.read_csv(workdir + 'data/raw/WRDS_2021/zero_curve_all.csv', parse_dates = ['date'])\n",
    "zero_column={\"date\": \"Date\", \"days\": \"Days\",  \"rate\" : \"Rate\"}\n",
    "zero_curve.rename(columns=zero_column, inplace=True)\n",
    "\n",
    "%run \"src/meme_stocks/functions_WRDS.py\"\n",
    "%run \"src/meme_stocks/functions_greeks.py\"\n",
    "df_rate = preclean_interest(zero_curve, max_days = 1500) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "864e2bc0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************\n",
      "processing 142943\n",
      "Stock 142943 exists already\n",
      "************ done *************\n"
     ]
    }
   ],
   "source": [
    "output_path = workdir + 'data/processed/intermediate/WRDS_2021/'\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "df_rate = preclean_interest(zero_curve, max_days = 1500)\n",
    "\n",
    "problem_stk_list = []\n",
    "for i in [109]: #list(range(100,len(df_stock_list))):\n",
    "    stkid = df_stock_list.loc[i, 'SecurityID']\n",
    "    ticker = df_stock_list.loc[i, 'Ticker']\n",
    "\n",
    "    print('*********************************************')\n",
    "    print('processing '+ str(stkid))        \n",
    "    \n",
    "    if os.path.exists(output_path + 'df_' + str(stkid) + '.csv') == True:\n",
    "        print('Stock '+ str(stkid) + ' exists already')        \n",
    "        continue\n",
    "    if os.path.exists(datadir + str(stkid)) == False:\n",
    "        print('Stock '+ str(stkid) + ' is not available') \n",
    "        problem_stk_list.append(stkid)\n",
    "        continue\n",
    "    else:        \n",
    "        df_stock, df_option, df_dividend, df_info = read_data(str(stkid))\n",
    "        if len(df_option) < 2:\n",
    "            print('Stock '+ str(stkid) + ' ' + ticker + ' is not available from OptionMerics')\n",
    "            continue\n",
    "        else:\n",
    "            df = preclean_data(df_option, df_stock, stkid)\n",
    "            df = merge_interest(df, df_rate)\n",
    "            df = prefilter_data(df)\n",
    "            # df_split = df_dividend[(df_dividend['DistributionType'] != 1)]\n",
    "        \n",
    "    if len(df) < 2:\n",
    "        problem_stk_list.append(stkid)\n",
    "        print('Stock '+ str(stkid) + ' ' + ticker + ' has insufficient observations')\n",
    "        continue     \n",
    "    else:     \n",
    "        for paydate in df_dividend.PaymentDate:\n",
    "            df = df[(df['Date'] != paydate)]\n",
    "            df = df[df['Date'] != paydate - BDay(1)]\n",
    "\n",
    "        df['SecurityID'] = stkid\n",
    "        df['StockTicker'] = ticker\n",
    "        \n",
    "        # adjust dividend rate\n",
    "        df_div = pd.read_csv(workdir + 'data/cleaned/synthetic/WRDS_2021/df_' + str(stkid) + '.csv', parse_dates = ['Date'])\n",
    "        df_div30 = df_div.loc[(df_div['Maturity'] == 30) & (df_div['CallPut'] == 'C'), ['Date', 'impl_div0', 'impl_cdiv0']].rename(columns = {'impl_div0': 'impl_div30', 'impl_cdiv0': 'impl_cdiv30'})\n",
    "        df_div60 = df_div.loc[(df_div['Maturity'] == 60) & (df_div['CallPut'] == 'C'), ['Date', 'impl_div0', 'impl_cdiv0']].rename(columns = {'impl_div0': 'impl_div60', 'impl_cdiv0': 'impl_cdiv60'})\n",
    "        df_div90 = df_div.loc[(df_div['Maturity'] == 90) & (df_div['CallPut'] == 'C'), ['Date', 'impl_div0', 'impl_cdiv0']].rename(columns = {'impl_div0': 'impl_div90', 'impl_cdiv0': 'impl_cdiv90'})\n",
    "        df_realdiv = df_div.loc[(df_div['Maturity'] == 90) & (df_div['CallPut'] == 'C'), ['Date', 'real_div0']].rename(columns = {'real_div0': 'real_div'})\n",
    "        df = df.merge(df_div30, how = 'left', on = 'Date')\n",
    "        df = df.merge(df_div60, how = 'left', on = 'Date')\n",
    "        df = df.merge(df_div90, how = 'left', on = 'Date')\n",
    "        df = df.merge(df_realdiv, how = 'left', on = 'Date')\n",
    "        df['real_div_yield'] = df['real_div'] / df['S0']\n",
    "        \n",
    "#         ## greeks:\n",
    "#         ## delta\n",
    "#         df['delta_bs_impl_cdiv90'] = bs_call_delta(vol=df['IV0'], S=df['S0'], K=df['K'], tau=df['tau'], r=df['r'], q=df['impl_cdiv90'])\n",
    "#         df['delta_bs_impl_cdiv_P'] = bs_put_delta(vol=df['IV0'], S=df['S0'], K=df['K'], tau=df['tau'], r=df['r'], q=df['impl_cdiv90'])        \n",
    "#         df.loc[df['CallPut'] == 'P', 'delta_bs_impl_cdiv90'] = df.loc[df['CallPut'] == 'P','delta_bs_impl_cdiv_P']\n",
    "#         del df['delta_bs_impl_cdiv_P']\n",
    "#         ## more version:\n",
    "#         # df['delta_bs_impl_cdiv60'] = bs_call_delta(vol=df['IV0'], S=df['S0'], K=df['K'], tau=df['tau'], r=df['r'], q=df['impl_cdiv60'])\n",
    "#         # df['delta_bs_impl_cdiv_P'] = bs_put_delta(vol=df['IV0'], S=df['S0'], K=df['K'], tau=df['tau'], r=df['r'], q=df['impl_cdiv60'])        \n",
    "#         # df.loc[df['CallPut'] == 'P', 'delta_bs_impl_cdiv60'] = df.loc[df['CallPut'] == 'P','delta_bs_impl_cdiv_P']\n",
    "#         # del df['delta_bs_impl_cdiv_P']\n",
    "#         # df['delta_bs_impl_cdiv30'] = bs_call_delta(vol=df['IV0'], S=df['S0'], K=df['K'], tau=df['tau'], r=df['r'], q=df['impl_cdiv30'])\n",
    "#         # df['delta_bs_impl_cdiv_P'] = bs_put_delta(vol=df['IV0'], S=df['S0'], K=df['K'], tau=df['tau'], r=df['r'], q=df['impl_cdiv30'])        \n",
    "#         # df.loc[df['CallPut'] == 'P', 'delta_bs_impl_cdiv30'] = df.loc[df['CallPut'] == 'P','delta_bs_impl_cdiv_P']\n",
    "#         # del df['delta_bs_impl_cdiv_P']        \n",
    "\n",
    "#         df['delta_bs_real_div'] = bs_call_delta(vol=df['IV0'], S=df['S0'], K=df['K'], tau=df['tau'], r=df['r'], q=df['real_div_yield'])\n",
    "#         df['delta_bs_real_div_P'] = bs_put_delta(vol=df['IV0'], S=df['S0'], K=df['K'], tau=df['tau'], r=df['r'], q=df['real_div_yield'])\n",
    "#         df.loc[df['CallPut'] == 'P', 'delta_bs_real_div'] = df.loc[df['CallPut'] == 'P','delta_bs_real_div_P']\n",
    "#         del df['delta_bs_real_div_P']\n",
    "\n",
    "#         ## gamma\n",
    "#         df['gamma_bs_impl_cdiv90'] = bs_gamma(vol=df['IV0'], S=df['S0'], K=df['K'], tau=df['tau'], r=df['r'], q=df['impl_cdiv90'])\n",
    "#         df['gamma_bs_real_div'] = bs_gamma(vol=df['IV0'], S=df['S0'], K=df['K'], tau=df['tau'], r=df['r'], q=df['real_div_yield'])\n",
    "\n",
    "#         ## vega\n",
    "#         df['vega_bs_impl_cdiv90'] = bs_vega(vol=df['IV0'], S=df['S0'], K=df['K'], tau=df['tau'], r=df['r'], q=df['impl_cdiv90'])\n",
    "#         df['vega_bs_real_div'] = bs_vega(vol=df['IV0'], S=df['S0'], K=df['K'], tau=df['tau'], r=df['r'], q=df['real_div_yield'])        \n",
    "        \n",
    "#         df['d0'] = df['real_div']        \n",
    "        df.to_csv(output_path + 'df_' + str(stkid) + '.csv', index = False)\n",
    "\n",
    "print('************ done *************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b07158-2334-4cda-ad97-2902f15d6127",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
