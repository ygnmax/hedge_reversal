{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88c54209",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "from pandas.tseries.offsets import BDay\n",
    "import os\n",
    "import getpass\n",
    "import time\n",
    "from random import randrange\n",
    "import math\n",
    "import wrds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10a81455",
   "metadata": {},
   "outputs": [],
   "source": [
    "if getpass.getuser() in ['ygnmax']:\n",
    "    if sys.platform == 'linux':\n",
    "        workdir = '/home/ygnmax/Dropbox/hedge_reversal/'\n",
    "    if sys.platform == 'win32':\n",
    "        workdir = 'C:/Users/ygnmax/Dropbox (Personal)/hedge_reversal/'\n",
    "os.chdir(workdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61a8c898-adcb-47b9-91b0-c577d63abee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stkid = 113993\n",
    "secid = stkid\n",
    "name = \"Game Stop\"\n",
    "ticker = \"GME\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bd923f-e912-461f-b09e-07e3473a50ab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Download and save as local files (could be deleted later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb425d7c-8ec4-4cea-b1a9-faa3871757c8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock 113993 option exists already\n",
      "Stock 113993 security_price exists already\n",
      "Stock 113993 distribution exists already\n",
      "Stock 113993 name exists already\n",
      "Stock 113993 standardized_option exists already\n",
      "Stock 113993 historical_volatility exists already\n",
      "Stock 113993 volatility_surface exists already\n",
      "Stock 113993 volume exists already\n",
      "************ done *************\n",
      "CPU times: user 306 ms, sys: 26.7 ms, total: 333 ms\n",
      "Wall time: 754 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "##################\n",
    "## Download GME:\n",
    "##################\n",
    "zero_curve = download_zero_curve(startdate = '2019-01-01', enddate = '2022-12-31')\n",
    "zero_curve.to_csv(workdir + 'data/raw/WRDS/zero_curve_all.csv', index = False)\n",
    "####################################################################\n",
    "## Download all the stocks which have options and save them locally\n",
    "####################################################################\n",
    "secid = 113993\n",
    "\n",
    "rel_path = 'data/raw/WRDS/'+ str(secid) + '/'\n",
    "os.makedirs(workdir + rel_path, exist_ok=True)\n",
    "\n",
    "if os.path.exists(workdir +  rel_path + 'option.csv') == True:\n",
    "    print('Stock '+ str(secid) + ' option exists already')        \n",
    "    pass\n",
    "else:\n",
    "    tplus = randrange(10)\n",
    "    time.sleep(10 + tplus)        \n",
    "    df_option = query_options(secid, startdate = '2019-01-01', enddate = '2022-12-31')\n",
    "    if len(df_option) > 0:\n",
    "        df_option.to_csv(workdir +  rel_path + 'option.csv', index = False)\n",
    "    else:\n",
    "        print(str(secid) + ' option is not available') \n",
    "\n",
    "if os.path.exists(workdir +  rel_path + 'security_price.csv') == True:\n",
    "    print('Stock '+ str(secid) + ' security_price exists already')        \n",
    "    pass\n",
    "else:\n",
    "    tplus = randrange(10)\n",
    "    time.sleep(10 + tplus)\n",
    "    df_stock = query_stock(secid, startdate = '2019-01-01', enddate = '2022-12-31')\n",
    "    if len(df_stock) > 0:        \n",
    "        df_stock.to_csv(workdir +  rel_path + 'security_price.csv', index = False)\n",
    "    else:\n",
    "        print(str(secid) + ' stock is not available') \n",
    "\n",
    "if os.path.exists(workdir +  rel_path + 'distribution.csv') == True:\n",
    "    print('Stock '+ str(secid) + ' distribution exists already')        \n",
    "    pass\n",
    "else:    \n",
    "    tplus = randrange(10)\n",
    "    time.sleep(10 + tplus)        \n",
    "    df_dividend = query_dividend(secid, startdate = '2019-01-01', enddate = '2022-12-31')\n",
    "    if len(df_dividend) > 0: \n",
    "        df_dividend.to_csv(workdir +  rel_path + 'distribution.csv', index = False)\n",
    "    else:\n",
    "        print(str(secid) + ' dividend is not available') \n",
    "\n",
    "if os.path.exists(workdir +  rel_path + 'name.csv') == True:\n",
    "    print('Stock '+ str(secid) + ' name exists already')        \n",
    "    pass\n",
    "else:\n",
    "    tplus = randrange(10)\n",
    "    time.sleep(10 + tplus)        \n",
    "    df_info = query_info(secid)\n",
    "    if len(df_info) > 0: \n",
    "        df_info.to_csv(workdir +  rel_path + 'name.csv', index = False)\n",
    "    else:\n",
    "        print(str(secid) + ' info is not available') \n",
    "\n",
    "if os.path.exists(workdir +  rel_path + 'standardized_option.csv') == True:\n",
    "    print('Stock '+ str(secid) + ' standardized_option exists already')        \n",
    "    pass\n",
    "else:\n",
    "    tplus = randrange(10)\n",
    "    time.sleep(10 + tplus)        \n",
    "    df_StdOption = query_StdOptions(secid, startdate = '2019-01-01', enddate = '2022-12-31')\n",
    "    if len(df_StdOption) > 0:         \n",
    "        df_StdOption.to_csv(workdir +  rel_path + 'standardized_option.csv', index = False)\n",
    "    else:\n",
    "        print(str(secid) + ' StdOption is not available') \n",
    "\n",
    "if os.path.exists(workdir +  rel_path + 'historical_volatility.csv') == True:\n",
    "    print('Stock '+ str(secid) + ' historical_volatility exists already')        \n",
    "    pass\n",
    "else:\n",
    "    tplus = randrange(10)\n",
    "    time.sleep(10 + tplus)        \n",
    "    df_hisvol = query_hisvol(secid, startdate = '2019-01-01', enddate = '2022-12-31')\n",
    "    if len(df_hisvol) > 0:              \n",
    "        df_hisvol.to_csv(workdir +  rel_path + 'historical_volatility.csv', index = False)\n",
    "    else:\n",
    "        print(str(secid) + ' historical vol is not available')     \n",
    "\n",
    "if os.path.exists(workdir +  rel_path + 'volatility_surface.csv') == True:\n",
    "    print('Stock '+ str(secid) + ' volatility_surface exists already')        \n",
    "    pass\n",
    "else:\n",
    "    tplus = randrange(10)\n",
    "    time.sleep(10 + tplus)        \n",
    "    df_volsurf = query_volsurf(secid, startdate = '2019-01-01', enddate = '2022-12-31')\n",
    "    if len(df_volsurf) > 0:          \n",
    "        df_volsurf.to_csv(workdir +  rel_path + 'volatility_surface.csv', index = False)\n",
    "    else:\n",
    "        print(str(secid) + ' vol surface is not available')       \n",
    "\n",
    "if os.path.exists(workdir +  rel_path + 'volume.csv') == True:\n",
    "    print('Stock '+ str(secid) + ' volume exists already')        \n",
    "    pass\n",
    "else:\n",
    "    tplus = randrange(10)\n",
    "    time.sleep(10 + tplus)        \n",
    "    df_volume = query_volume(secid, startdate = '2019-01-01', enddate = '2022-12-31')\n",
    "    if len(df_volume) > 0:         \n",
    "        df_volume.to_csv(workdir +  rel_path + 'volume.csv', index = False)\n",
    "    else:\n",
    "        print(str(secid) + ' volume is not available')           \n",
    "\n",
    "print('************ done *************')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad69a5ed-27c4-402a-8dd0-20eb60625451",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Read (could be replaced by the Download section and deleted later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ce067ef-ca33-468e-a2a7-13c668b10e43",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(757, 13)\n",
      "(835990, 26)\n",
      "(1, 15)\n",
      "(33571, 3)\n"
     ]
    }
   ],
   "source": [
    "# read:\n",
    "rel_path = 'data/raw/WRDS/'+ str(secid) + '/'\n",
    "df_option = pd.read_csv(workdir +  rel_path + 'option.csv', parse_dates = ['date', 'exdate', 'last_date'], low_memory=False)\n",
    "df_stock = pd.read_csv(workdir +  rel_path + 'security_price.csv', parse_dates = ['date'], low_memory=False)\n",
    "df_dividend = pd.read_csv(workdir +  rel_path + 'distribution.csv', parse_dates = ['record_date', 'ex_date','declare_date','payment_date'])\n",
    "zero_curve = pd.read_csv(workdir + 'data/raw/WRDS/zero_curve_all.csv', parse_dates = ['date'], low_memory=False)\n",
    "stock_column={\"secid\": \"SecurityID\",\n",
    "              \"date\": \"Date\",\n",
    "              \"low\" : \"BidLow\",\n",
    "              \"high\" : \"AskHigh\",\n",
    "              \"open\" : \"OpenPrice\",\n",
    "              \"high\" :  \"AskHigh\",\n",
    "              \"close\" : \"ClosePrice\",\n",
    "              \"volume\" : \"Volume\",\n",
    "              \"return\": \"TotalReturn\",\n",
    "              \"cfadj\" : \"AdjustmentFactor\",\n",
    "              \"shrout\" : \"SharesOutstanding\",\n",
    "              \"cfret\" : \"AdjustmentFactor2\" \n",
    "             }\n",
    "option_column={\"secid\": \"SecurityID\",\n",
    "               \"date\": \"Date\",\n",
    "               \"exdate\" : \"Expiration\",\n",
    "               \"strike_price\" :  \"Strike\",\n",
    "               \"cp_flag\" : \"CallPut\",\n",
    "               \"best_bid\" : \"BestBid\",\n",
    "               \"best_offer\" : \"BestOffer\",\n",
    "               \"impl_volatility\" : \"ImpliedVolatility\",\n",
    "               \"delta\" : \"Delta\",\n",
    "               \"gamma\" : \"Gamma\",\n",
    "               \"vega\" : \"Vega\",\n",
    "               \"theta\" : \"Theta\",\n",
    "               \"volume\" : \"Volume\",\n",
    "               \"open_interest\": \"OpenInterest\",\n",
    "               \"last_date\" : \"LastTradeDate\",\n",
    "               \"contract_size\" : \"ContractSize\",\n",
    "               \"optionid\" : \"OptionID\" \n",
    "               }\n",
    "div_column={\"secid\": \"SecurityID\",\n",
    "            \"record_date\": \"RecordDate\",\n",
    "            \"ticker\" : \"Ticker\",\n",
    "            \"issuer\" :  \"IssuerDescription\",\n",
    "            \"distr_type\": \"DistributionType\",\n",
    "            \"amount\" : \"Amount\",\n",
    "            \"ex_date\": \"ExDate\",\n",
    "            \"declare_date\": \"DeclareDate\",\n",
    "            \"payment_date\": \"PaymentDate\"\n",
    "            }\n",
    "zero_column={\"date\": \"Date\", \"days\": \"Days\",  \"rate\" : \"Rate\"}\n",
    "df_stock.rename(columns=stock_column, inplace=True)\n",
    "df_stock['AdjClosePrice'] = df_stock['ClosePrice'] * df_stock['AdjustmentFactor'] / df_stock.loc[len(df_stock)-1, 'AdjustmentFactor']\n",
    "df_stock['AdjClosePrice2'] = df_stock['ClosePrice'] * df_stock['AdjustmentFactor2'] / df_stock.loc[len(df_stock)-1, 'AdjustmentFactor2']\n",
    "df_option.rename(columns=option_column, inplace=True)\n",
    "df_dividend.rename(columns=div_column, inplace=True)\n",
    "zero_curve.rename(columns=zero_column, inplace=True)\n",
    "print(df_stock.shape)\n",
    "print(df_option.shape)\n",
    "print(df_dividend.shape)\n",
    "print(zero_curve.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80096092-1088-4a1d-9879-7f358345694b",
   "metadata": {},
   "source": [
    "# Download directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bcdb4bb-5c9a-4c9d-bfde-419e103f5ad1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading library list...\n",
      "Done\n",
      "113993 option price is not available in 2022\n"
     ]
    }
   ],
   "source": [
    "# Get options data and security prices\n",
    "def query_options(secid, startdate = '2019-01-01', enddate = '2022-12-31'):\n",
    "    '''\n",
    "    secid: int. Example: secid = 113993\n",
    "    startdate: str. Example: startdate = '2003-01-06'\n",
    "    enddate: str. Example: enddate = '2004-06-07'\n",
    "    '''\n",
    "    \n",
    "    startyear = int(startdate[0:4])\n",
    "    endyear = int(enddate[0:4])\n",
    "\n",
    "    df_all = pd.DataFrame()\n",
    "    for yr in list(range(startyear, endyear+1, 1)):\n",
    "        # Get the data for the options\n",
    "        sql = '''\n",
    "        SELECT *\n",
    "        FROM optionm.opprcd%s\n",
    "        WHERE secid=%s\n",
    "        ORDER BY date ASC\n",
    "        ''' % (yr, secid)\n",
    "        try:\n",
    "            df_tmp = db.raw_sql(sql, date_cols=['date', 'exdate', 'last_date'])\n",
    "            df_tmp[['secid', 'strike_price', 'optionid', 'am_settlement', 'contract_size']] = df_tmp[['secid', 'strike_price', 'optionid', 'am_settlement', 'contract_size']].astype('int', errors = 'ignore')\n",
    "            df_all = pd.concat([df_all, df_tmp])\n",
    "        except:\n",
    "            print(str(secid), 'option price is not available in', str(yr))\n",
    "            pass\n",
    "    df_all = df_all.reset_index().drop(columns='index')\n",
    "    return df_all\n",
    "\n",
    "def query_stock(secid, startdate = '2019-01-01', enddate = '2022-12-31'):\n",
    "    \"\"\"\n",
    "    Function for query stock price during a certain period\n",
    "    output: a dataframe of stock daily trading information, including the open, high, low, close, adjustment factor, volumes\n",
    "    \"\"\"   \n",
    "    sql = '''\n",
    "    SELECT *\n",
    "    FROM optionm.secprd\n",
    "    WHERE secid=%s\n",
    "    AND date BETWEEN '%s' AND '%s'\n",
    "    ORDER BY date ASC\n",
    "    ''' % (secid, startdate, enddate)\n",
    "\n",
    "    output = db.raw_sql(sql)\n",
    "    if len(output) > 0:\n",
    "        output[['secid', 'volume', 'shrout']] = output[['secid', 'volume', 'shrout']].astype('int') \n",
    "        \n",
    "    return output\n",
    "\n",
    "def query_dividend(secid, startdate = '2019-01-01', enddate = '2022-12-31'):\n",
    "    \"\"\"\n",
    "    Function for query stock distribution inforamtion during a certain period\n",
    "    output: a dataframe of stock distribution information, including dividend, split, spin-off, etc.\n",
    "    \"\"\"     \n",
    "    # get distributions\n",
    "    sql = '''\n",
    "    SELECT *\n",
    "    FROM optionm.distrd\n",
    "    WHERE secid=%s\n",
    "    ''' % secid\n",
    "    \n",
    "    dist = db.raw_sql(sql, date_cols=['ex_date'])\n",
    "    if len(dist) > 0:\n",
    "        dist['secid'] = dist['secid'].astype('int')\n",
    "        dist = dist[(startdate <= dist['ex_date']) & (dist['ex_date']<=enddate)].reset_index(drop = True)        \n",
    "    return dist\n",
    "\n",
    "def download_zero_curve(startdate = '2019-01-01', enddate = '2022-12-31'):\n",
    "    sql = '''\n",
    "    SELECT *\n",
    "    FROM optionm.zerocd\n",
    "    WHERE date BETWEEN '%s' AND '%s'\n",
    "    ''' % (startdate, enddate)\n",
    "    zero_curve = db.raw_sql(sql, date_cols=['date'])\n",
    "    zero_curve['days'] = zero_curve['days'].astype('int')\n",
    "    return zero_curve\n",
    "\n",
    "with wrds.Connection(wrds_username='ygnmaxwharton') as db:\n",
    "    zero_curve = download_zero_curve(startdate = '2019-01-01', enddate = '2022-12-31')\n",
    "    df_option = query_options(secid, startdate = '2019-01-01', enddate = '2022-12-31')\n",
    "    df_stock = query_stock(secid, startdate = '2019-01-01', enddate = '2022-12-31')\n",
    "    df_dividend = query_dividend(secid, startdate = '2019-01-01', enddate = '2022-12-31')\n",
    "    \n",
    "stock_column={\"secid\": \"SecurityID\",\n",
    "              \"date\": \"Date\",\n",
    "              \"low\" : \"BidLow\",\n",
    "              \"high\" : \"AskHigh\",\n",
    "              \"open\" : \"OpenPrice\",\n",
    "              \"high\" :  \"AskHigh\",\n",
    "              \"close\" : \"ClosePrice\",\n",
    "              \"volume\" : \"Volume\",\n",
    "              \"return\": \"TotalReturn\",\n",
    "              \"cfadj\" : \"AdjustmentFactor\",\n",
    "              \"shrout\" : \"SharesOutstanding\",\n",
    "              \"cfret\" : \"AdjustmentFactor2\" \n",
    "             }\n",
    "option_column={\"secid\": \"SecurityID\",\n",
    "               \"date\": \"Date\",\n",
    "               \"exdate\" : \"Expiration\",\n",
    "               \"strike_price\" :  \"Strike\",\n",
    "               \"cp_flag\" : \"CallPut\",\n",
    "               \"best_bid\" : \"BestBid\",\n",
    "               \"best_offer\" : \"BestOffer\",\n",
    "               \"impl_volatility\" : \"ImpliedVolatility\",\n",
    "               \"delta\" : \"Delta\",\n",
    "               \"gamma\" : \"Gamma\",\n",
    "               \"vega\" : \"Vega\",\n",
    "               \"theta\" : \"Theta\",\n",
    "               \"volume\" : \"Volume\",\n",
    "               \"open_interest\": \"OpenInterest\",\n",
    "               \"last_date\" : \"LastTradeDate\",\n",
    "               \"contract_size\" : \"ContractSize\",\n",
    "               \"optionid\" : \"OptionID\" \n",
    "               }\n",
    "div_column={\"secid\": \"SecurityID\",\n",
    "            \"record_date\": \"RecordDate\",\n",
    "            \"ticker\" : \"Ticker\",\n",
    "            \"issuer\" :  \"IssuerDescription\",\n",
    "            \"distr_type\": \"DistributionType\",\n",
    "            \"amount\" : \"Amount\",\n",
    "            \"ex_date\": \"ExDate\",\n",
    "            \"declare_date\": \"DeclareDate\",\n",
    "            \"payment_date\": \"PaymentDate\"\n",
    "            }\n",
    "zero_column={\"date\": \"Date\", \"days\": \"Days\",  \"rate\" : \"Rate\"}\n",
    "df_stock.rename(columns=stock_column, inplace=True)\n",
    "df_stock['AdjClosePrice'] = df_stock['ClosePrice'] * df_stock['AdjustmentFactor'] / df_stock.loc[len(df_stock)-1, 'AdjustmentFactor']\n",
    "df_stock['AdjClosePrice2'] = df_stock['ClosePrice'] * df_stock['AdjustmentFactor2'] / df_stock.loc[len(df_stock)-1, 'AdjustmentFactor2']\n",
    "df_stock['Date'] = pd.to_datetime(df_stock['Date'])\n",
    "df_option.rename(columns=option_column, inplace=True)\n",
    "df_dividend.rename(columns=div_column, inplace=True)\n",
    "zero_curve.rename(columns=zero_column, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552e907d-aef8-4e9a-9590-7b81893d4dbc",
   "metadata": {},
   "source": [
    "# Clean yield curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be3ac2f3-aff6-49ef-b6fc-866cb0e60023",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# clean yield curve\n",
    "def preclean_interest(df_zero_curve, max_days = 1500):\n",
    "\n",
    "    yield_curve = pd.DataFrame()\n",
    "    for d, group in df_zero_curve.groupby('Date'):\n",
    "        group['Rate'] = pd.to_numeric(group['Rate'], 'coerce')\n",
    "\n",
    "        new_row = pd.DataFrame({'Date': d, 'Days': 1, 'Rate': np.nan}, index =[0])\n",
    "        group = pd.concat([new_row, group]).reset_index(drop = True)\n",
    "        group = group.sort_values(['Date', 'Days'])\n",
    "        group = group.fillna(method = 'bfill')\n",
    "\n",
    "        yield_curve = pd.concat([yield_curve, group]).reset_index(drop = True)\n",
    "    \n",
    "    ## 1.3.4 Interpolate the interest rate\n",
    "    num_days = np.arange(1, max_days + 5)\n",
    "    df_rate = pd.DataFrame()\n",
    "    holidays = []\n",
    "    for key, df_group in yield_curve.groupby('Date'):\n",
    "        res = pd.DataFrame()\n",
    "        res['Days'] = num_days\n",
    "        if len(df_group['Days']) <= 1:\n",
    "            holidays.append(key.date())\n",
    "            res['Rate'] = np.nan\n",
    "            res['Date'] = key\n",
    "            df_rate = df_rate.append(res)\n",
    "        else:\n",
    "            func = interp1d(df_group['Days'], df_group['Rate'], bounds_error=False, fill_value=np.nan)\n",
    "            res['Rate'] = func(num_days)\n",
    "            res['Date'] = key\n",
    "            df_rate = df_rate.append(res)\n",
    "    \n",
    "    ## 1.3.5 Output divided by 100\n",
    "    df_rate['Rate'] = df_rate['Rate'] / 100.0  \n",
    "    df_rate = df_rate.reset_index(drop = True)    \n",
    "    \n",
    "    return df_rate\n",
    "\n",
    "df_rate = preclean_interest(zero_curve, max_days = 1500) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3912e92-9653-4bb5-a83c-49c1c59cf1ad",
   "metadata": {},
   "source": [
    "# Get the ATM options, in order to prepare to construct tracer options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5d95a26-2d88-4688-942c-21368ef4f66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_interest(df, df_rate):\n",
    "    # merge interest rate to expiry\n",
    "    #----------------------------------------------------------\n",
    "    # merge option price with overnight rate as short rate\n",
    "    #----------------------------------------------------------    \n",
    "    df_one_day = df_rate[df_rate['Days'] == 1]\n",
    "\n",
    "    df = df.merge(df_one_day[['Date', 'Rate']], how = 'left', on = 'Date')\n",
    "    df.rename(columns = {'Rate': 'short_rate'}, inplace = True)\n",
    "    #--------------------------------------------------------------------------------\n",
    "    # match option price with interpolated yield curve (calender days to expiry)\n",
    "    #--------------------------------------------------------------------------------\n",
    "    df = df.merge(df_rate, how = 'left', left_on = ['Date', 'Maturity'], right_on = ['Date', 'Days'])\n",
    "    df.rename(columns = {'Rate': 'r'}, inplace = True)\n",
    "    del df['Days']\n",
    "    return df\n",
    "\n",
    "def get_closest_ATM_option(df_stock, df_rate, df_raw, optype, target_maturity, stkid, ticker):    \n",
    "    df = df_raw[df_raw['ContractSize'] > 0].copy()\n",
    "    df = df[df['CallPut'] == optype]\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df['Expiration'] = pd.to_datetime(df['Expiration'])\n",
    "    df['K'] = df['Strike'] / 1000.0\n",
    "    df['V0'] = (df['BestBid'] + df['BestOffer'])/2\n",
    "    df['Maturity'] = df['Expiration'] - df['Date']\n",
    "    df['Maturity'] = df['Maturity'].dt.days\n",
    "    df['tau'] = df['Maturity'] / 360\n",
    "\n",
    "    df['IV0'] = df['ImpliedVolatility']\n",
    "\n",
    "    df = df[['Date', 'K', 'Expiration',\n",
    "           'CallPut', 'BestBid', 'BestOffer', 'LastTradeDate', 'Volume',\n",
    "           'IV0', 'Delta', 'Gamma', 'Vega', 'Theta', 'OptionID', \n",
    "           'V0', 'Maturity', 'tau']]\n",
    "    df = df.sort_values(by = ['Date', 'Expiration', 'CallPut', 'K'])\n",
    "\n",
    "    df_stk = df_stock.copy()\n",
    "    #     df_stk = df_stk[df_stk['SecurityID'] == stkid]\n",
    "    df_stk['S0'] = df_stk['ClosePrice']\n",
    "\n",
    "    #----------------------------------------------------\n",
    "    # merge option price with index/underlying price\n",
    "    #----------------------------------------------------\n",
    "    df = df.merge(df_stk[['Date', 'S0', 'AdjClosePrice', 'AdjClosePrice2', 'AdjustmentFactor', 'AdjustmentFactor2']], \n",
    "                  how = 'inner', on = 'Date')\n",
    "\n",
    "    df['M0'] = df['S0'] / df['K']\n",
    "\n",
    "    df = merge_interest(df, df_rate)\n",
    "\n",
    "    df['TargetMaturity'] = target_maturity\n",
    "    df = df.merge(df_rate, how = 'left', left_on = ['Date', 'TargetMaturity'], right_on =['Date', 'Days'])\n",
    "    df.rename(columns = {'Rate': 'TargetRate'}, inplace = True)\n",
    "\n",
    "\n",
    "    df_ATM = pd.DataFrame()\n",
    "    for dt, df_tmp in df.groupby('Date'):\n",
    "\n",
    "        df_tmp['diff'] = df_tmp['Maturity'] - target_maturity\n",
    "        if target_maturity not in np.unique(df_tmp['Maturity']):\n",
    "\n",
    "            neg_diff_list = sorted([i for i in np.unique(df_tmp['diff']) if i < 0])\n",
    "            pos_diff_list = sorted([i for i in np.unique(df_tmp['diff']) if i > 0], reverse = True)\n",
    "            if (len(neg_diff_list) > 0) & (len(pos_diff_list) > 0):\n",
    "                neg_diff = np.max(neg_diff_list)\n",
    "                pos_diff = np.min(pos_diff_list)\n",
    "\n",
    "                df_neg_M0 = df_tmp[df_tmp['diff'].isin([neg_diff])]\n",
    "\n",
    "                df_neg_M0_less1 = [i for i in np.unique(df_neg_M0['M0'].values) if i < 1]\n",
    "                df_neg_M0_more1 = [i for i in np.unique(df_neg_M0['M0'].values) if i > 1]\n",
    "                if len(df_neg_M0_less1) > 0 & len(df_neg_M0_more1) > 0:            \n",
    "                    maturity_range = [neg_diff, pos_diff]\n",
    "\n",
    "\n",
    "\n",
    "            elif (len(neg_diff_list) == 0) & (len(pos_diff_list) > 0):\n",
    "                neg_diff = 0\n",
    "                pos_diff = np.min(pos_diff_list)\n",
    "            elif (len(neg_diff_list) > 0) & (len(pos_diff_list) == 0):\n",
    "                neg_diff = np.max(neg_diff_list)\n",
    "                pos_diff = 0\n",
    "            else:\n",
    "                print('not available')\n",
    "                break\n",
    "\n",
    "            maturity_range = [neg_diff, pos_diff]\n",
    "            df_tmp = df_tmp[df_tmp['diff'].isin(maturity_range)]\n",
    "\n",
    "\n",
    "            loc = np.abs(df_tmp['M0'] - 1) < 0.01\n",
    "            if True in list(loc):\n",
    "                idx = loc[loc == True].index\n",
    "                df_ATM_one = df_tmp.loc[idx, ]\n",
    "            else:\n",
    "                df_neg = df_tmp[df_tmp['diff'] == neg_diff]\n",
    "                if len(df_neg) > 0:\n",
    "                    df_neg_M0_less1 = [i for i in np.unique(df_neg['M0'].values) if i < 1]\n",
    "                    df_neg_M0_more1 = [i for i in np.unique(df_neg['M0'].values) if i > 1]\n",
    "                    if (len(df_neg_M0_less1) > 0) & (len(df_neg_M0_more1) > 0):\n",
    "                        moneyness_range = [np.min(df_neg_M0_more1), np.max(df_neg_M0_less1)]\n",
    "                    elif (len(df_neg_M0_less1) == 0) & (len(df_neg_M0_more1) > 0):\n",
    "                        moneyness_range = [np.min(df_neg_M0_more1)]\n",
    "                    elif (len(df_neg_M0_less1) > 0) & (len(df_neg_M0_more1) == 0):\n",
    "                        moneyness_range = [np.max(df_neg_M0_less1)]\n",
    "                    df_neg = df_neg[df_neg['M0'].isin(moneyness_range)]\n",
    "\n",
    "                df_pos = df_tmp[df_tmp['diff'] == pos_diff]\n",
    "                if len(df_pos) > 0:\n",
    "                    df_pos_M0_less1 = [i for i in np.unique(df_pos['M0'].values) if i < 1]\n",
    "                    df_pos_M0_more1 = [i for i in np.unique(df_pos['M0'].values) if i > 1]\n",
    "                    if (len(df_pos_M0_less1) > 0) & (len(df_pos_M0_more1) > 0):\n",
    "                        moneyness_range = [np.min(df_pos_M0_more1), np.max(df_pos_M0_less1)]\n",
    "                    elif (len(df_pos_M0_less1) == 0) & (len(df_pos_M0_more1) > 0):\n",
    "                        moneyness_range = [np.min(df_pos_M0_more1)]\n",
    "                    elif (len(df_pos_M0_less1) > 0) & (len(df_pos_M0_more1) == 0):\n",
    "                        moneyness_range = [np.max(df_pos_M0_less1)]\n",
    "                    df_pos = df_pos[df_pos['M0'].isin(moneyness_range)]\n",
    "\n",
    "                df_ATM_one = pd.concat([df_neg, df_pos])\n",
    "        else:\n",
    "            df_tmp = df_tmp.loc[df_tmp['Maturity'] == target_maturity, :]\n",
    "\n",
    "            loc = np.abs(df_tmp['M0'] - 1) < 0.01\n",
    "            if True in list(loc):\n",
    "                idx = loc[loc == True].index\n",
    "                df_ATM_one = df_tmp.loc[idx, ]\n",
    "            else:\n",
    "                df_tmp_M0_less1 = [i for i in np.unique(df_tmp['M0'].values) if i < 1]\n",
    "                df_tmp_M0_more1 = [i for i in np.unique(df_tmp['M0'].values) if i > 1]\n",
    "                if (len(df_tmp_M0_less1) > 0) & (len(df_tmp_M0_more1) > 0):\n",
    "                    moneyness_range = [np.min(df_tmp_M0_more1), np.max(df_tmp_M0_less1)]\n",
    "                elif (len(df_tmp_M0_less1) == 0) & (len(df_tmp_M0_more1) > 0):\n",
    "                    moneyness_range = [np.min(df_tmp_M0_more1)]\n",
    "                elif (len(df_tmp_M0_less1) > 0) & (len(df_tmp_M0_more1) == 0):\n",
    "                    moneyness_range = [np.max(df_tmp_M0_less1)]            \n",
    "                df_ATM_one = df_tmp[df_tmp['M0'].isin(moneyness_range)]   \n",
    "\n",
    "        df_ATM = pd.concat([df_ATM, df_ATM_one])\n",
    "    df_ATM = df_ATM.reset_index(drop = True)\n",
    "    df_ATM['Ticker'] = ticker\n",
    "    df_ATM['SecurityID'] = stkid\n",
    "    \n",
    "    return df_ATM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fef04c-ae0c-4b37-a644-9f7d47839f6c",
   "metadata": {},
   "source": [
    "# Define American Pricer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fba27b10-b2df-43c9-adc3-7c8e03da19f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools as ft\n",
    "import scipy as sp\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def bintree(S, u, d, n, t, r, ex_div):\n",
    "    '''\n",
    "    Binomial tree with dividend adjustment\n",
    "    returns a list containing the binomial tree\n",
    "    \n",
    "    S: Stock Price\n",
    "    u: np.exp(sigma * np.sqrt(t))\n",
    "    d: 1.0 / u\n",
    "    n: Steps of Binomial Tree\n",
    "    t: time interval per steps (also the annualized maturity per steps)\n",
    "    ex_div: Dividends, which are given in the format np.array([[time_to_ExDate, ExDate_to_Maturity, dividend]]) \n",
    "    time_to_ExDate and ExDate_to_Maturity are annualized \n",
    "    I assume each of steps of the binomial tree evenly spreads out the time to maturity for this option\n",
    "    '''   \n",
    "#     print(\"ex_div\", ex_div)\n",
    "    # Creating a binomial tree with dividends adjustment\n",
    "    time_to_ex = ex_div[0, 0]\n",
    "    ex_to_mat = ex_div[0, 1]\n",
    "    div = ex_div[0, 2]\n",
    "    \n",
    "    S0 = S - div*np.exp(-r* time_to_ex/n)\n",
    "    \n",
    "    tree = [np.array([S0])]\n",
    "    for i in range(n):\n",
    "        tree.append(np.concatenate((tree[-1][:1]*u, tree[-1]*d))) \n",
    "\n",
    "    if (len(ex_div) > 0):\n",
    "        n_ex = n * time_to_ex / (time_to_ex + ex_to_mat)\n",
    "        n_ex = math.ceil(n_ex)\n",
    "        div_adj = [np.exp(-r * t * (n_ex - i)) for i in range(0,n_ex)]\n",
    "        tree[0:n_ex] = list(map(lambda x, y: x + y, tree[0:n_ex], div_adj))\n",
    "\n",
    "    return tree\n",
    "\n",
    "def invalue_func(S, K, CallPut):\n",
    "    '''\n",
    "    Intrinsic value\n",
    "    S: Stock Price\n",
    "    K: Strike Price\n",
    "    CallPut: OptType\n",
    "    '''      \n",
    "    if (CallPut=='C'): \n",
    "        return np.maximum(S-K, 0)\n",
    "    else: \n",
    "        return np.maximum(K-S, 0)\n",
    "    \n",
    "def am_exercise(discount, p, payoff_tree, in_value): \n",
    "    '''\n",
    "    discount: discount factor\n",
    "    p: risk-neutral probability\n",
    "    tree: result of binomial tree\n",
    "    in_value : intrinsic value    \n",
    "    '''      \n",
    "    # Selecting maximum between continuation and intrinsic value\n",
    "    return np.maximum(in_value, discount*(payoff_tree[:-1]*p + payoff_tree[1:]*(1-p)))\n",
    "\n",
    "    \n",
    "def am_option_price(am_exercise, invalue_func, S, T, r, sigma, n, ex_div):\n",
    "    '''\n",
    "    American Option Pricer with dividends adjustment\n",
    "    am_func: function of comparing the intrinsic value and the value calulated by the binomial tree\n",
    "    invalue_func: function of calculating intrinsic value \n",
    "    S: Stock Price\n",
    "    T: Time To Maturity (annualized)\n",
    "    n: Steps of Binomial Tree\n",
    "    t: time interval per steps (also the annualized maturity per steps)\n",
    "    r: Interest Rate\n",
    "    sigma: Volatility\n",
    "    ex_div: Dividends, which are given in the format np.array([[time_to_ExDate, ExDate_to_Maturity, dividend]])\n",
    "    time_to_ExDate and ExDate_to_Maturity are annualized \n",
    "    ''' \n",
    "    t = T / n\n",
    "    u = np.exp(sigma * np.sqrt(t))\n",
    "    d = 1.0 / u\n",
    "    if u - d == 0:\n",
    "        print(f\"u: {u}\", f\", d: {d}\", f\", sigma: {sigma}\", f\", t: {t}\", f\", n: {n}\")\n",
    "        print(\"stock price:\", S )\n",
    "    p = (np.exp(r * t) - d)/(u - d)\n",
    "    \n",
    "    # Creating the stock price binomial tree\n",
    "    stock_tree = bintree(S, u, d, n, t, r, ex_div)[::-1]\n",
    "    \n",
    "    # Discounting through the tree with american exercise option\n",
    "    # payoff binomial tree: map(invalue_func, stock_tree)\n",
    "    result = ft.reduce(ft.partial(am_exercise, np.exp(-r*t), p), map(invalue_func, stock_tree))\n",
    "    return result[0]\n",
    "\n",
    "AM = ft.partial(am_option_price, am_exercise)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630b5266-992e-43ce-851b-e61af5db7eb6",
   "metadata": {},
   "source": [
    "# Validate the American Pricer by example (could be deleled later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9766f654-0af0-467a-87e6-85fd33297114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9 s, sys: 97.7 ms, total: 9.1 s\n",
      "Wall time: 9.09 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "target_maturity = 60\n",
    "df_ATM_C = get_closest_ATM_option(df_stock, df_rate, df_raw = df_option, optype = 'C', target_maturity = target_maturity, stkid = stkid, ticker = ticker)\n",
    "df_ATM_P = get_closest_ATM_option(df_stock, df_rate, df_raw = df_option, optype = 'P', target_maturity = target_maturity, stkid = stkid, ticker = ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09f67d55-698e-4d64-a3c3-487e2b5714d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date 2019-03-05 00:00:00, Option: C,  At-The-Money\n",
      "Stock Price 11.6, Strike Price: 11.6, Target Maturity (days): 60, Maturity (annualized): 0.23809523809523808, Interest Rate: 0.026002431428571428\n",
      "Implied Volatility 0.508963, Option Price 1.155,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ExDate</th>\n",
       "      <th>Amount</th>\n",
       "      <th>DeclareDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-03-14</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2019-03-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ExDate  Amount DeclareDate\n",
       "0 2019-03-14    0.38  2019-03-04"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 130\n",
    "\n",
    "date = df_ATM_C.Date[idx]\n",
    "S = df_ATM_C.S0.values[idx]\n",
    "X = df_ATM_C.S0.values[idx]\n",
    "CP = df_ATM_C.CallPut.values[idx]\n",
    "r = df_ATM_C.TargetRate.values[idx]\n",
    "MBBO_synthetic = df_ATM_C.V0[idx]\n",
    "IV_0 = df_ATM_C.IV0[idx]\n",
    "\n",
    "target_maturity = 60\n",
    "T = target_maturity/252\n",
    "\n",
    "print(f\"Date {date},\", f\"Option: {CP}, \", f\"At-The-Money\")\n",
    "print(f\"Stock Price {S},\", f\"Strike Price: {X},\", f\"Target Maturity (days): {target_maturity},\", f\"Maturity (annualized): {T},\", f\"Interest Rate: {r}\" )\n",
    "print(f\"Implied Volatility {IV_0},\", f\"Option Price {MBBO_synthetic},\" )\n",
    "\n",
    "dividends = df_dividend.loc[df_dividend['DistributionType'] == 1, ['ExDate', 'Amount', 'DeclareDate']] # dividend distribution\n",
    "dividends = dividends.reset_index(drop = True)\n",
    "dividends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "156db752-bef4-4c0b-b556-92f4ce98f3a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03571429, 0.20238095, 0.38      ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if len(dividends) > 0:\n",
    "    ### determine whether today (the date of this observation) is between the decalare date and ex date\n",
    "    div_idx = []\n",
    "    for j in dividends.index:\n",
    "        if (dividends.loc[j, 'DeclareDate'] < date) & (date < dividends.loc[j, 'ExDate']):\n",
    "            div_idx.append(j)\n",
    "    dividends = dividends.loc[div_idx, :]\n",
    "    \n",
    "    if len(dividends) > 0:\n",
    "        expir_date = np.unique(df_ATM_C.loc[idx, 'Date'] + pd.DateOffset(days = target_maturity))[0]\n",
    "        time_to_ExDate = np.array([(t-date).days / 252 for t in dividends.ExDate])                        # time to Ex date (annualized divided by 252 days per year)\n",
    "        ExDate_to_Maturity = np.array([(expir_date-t).days / 252 for t in dividends.ExDate])              # Ex date to Maturity date (annualized divided by 252 days per year)\n",
    "        div_annual = np.array([time_to_ExDate, ExDate_to_Maturity, dividends.Amount]).T                   # Dividend table with maturity of Ex date\n",
    "\n",
    "        div_annual = div_annual[(div_annual[:,0]>0) & (div_annual[:,1]>0)]\n",
    "    else:\n",
    "        div_annual = np.array([[1, 1, 0.0]])\n",
    "else:\n",
    "    div_annual = np.array([[1, 1, 0.0]])\n",
    "    \n",
    "div_annual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e8af9d32-73b1-4c76-bcfe-7c5328c62b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.554525481154022"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 500\n",
    "sigma = 0.765\n",
    "\n",
    "AM(ft.partial(invalue_func, K=X, CallPut=CP),S, T, r, sigma, n, div_annual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8e31484e-18b3-424a-9f50-d1f166099448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([12.21879784]),\n",
       " array([13.62519079, 10.97016275]),\n",
       " array([14.20771562, 11.22003529,  8.8606216 ]),\n",
       " array([15.98782081, 12.6258097 ,  9.97078166,  7.87406822]),\n",
       " array([17.99095796, 14.20771562, 11.22003529,  8.8606216 ,  6.99735901]),\n",
       " array([20.24507104, 15.98782081, 12.6258097 ,  9.97078166,  7.87406822,\n",
       "         6.21826377]),\n",
       " array([22.78160521, 17.99095796, 14.20771562, 11.22003529,  8.8606216 ,\n",
       "         6.99735901,  5.52591403]),\n",
       " array([25.63594541, 20.24507104, 15.98782081, 12.6258097 ,  9.97078166,\n",
       "         7.87406822,  6.21826377,  4.91065142]),\n",
       " array([28.84791001, 22.78160521, 17.99095796, 14.20771562, 11.22003529,\n",
       "         8.8606216 ,  6.99735901,  5.52591403,  4.36389298]),\n",
       " array([32.46230628, 25.63594541, 20.24507104, 15.98782081, 12.6258097 ,\n",
       "         9.97078166,  7.87406822,  6.21826377,  4.91065142,  3.87801134]),\n",
       " array([36.52955549, 28.84791001, 22.78160521, 17.99095796, 14.20771562,\n",
       "        11.22003529,  8.8606216 ,  6.99735901,  5.52591403,  4.36389298,\n",
       "         3.44622841])]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 10\n",
    "t = T / n\n",
    "u = np.exp(sigma * np.sqrt(t))\n",
    "d = 1.0 / u\n",
    "p = (np.exp(r * t) - d)/(u - d)\n",
    "\n",
    "bintree(S, u, d, n, t, r, div_annual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9304f799-2c7e-42a3-92fb-0e5e4559bc45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([11.22003529]),\n",
       " array([12.6258097 ,  9.97078166]),\n",
       " array([14.20771562, 11.22003529,  8.8606216 ]),\n",
       " array([15.98782081, 12.6258097 ,  9.97078166,  7.87406822]),\n",
       " array([17.99095796, 14.20771562, 11.22003529,  8.8606216 ,  6.99735901]),\n",
       " array([20.24507104, 15.98782081, 12.6258097 ,  9.97078166,  7.87406822,\n",
       "         6.21826377]),\n",
       " array([22.78160521, 17.99095796, 14.20771562, 11.22003529,  8.8606216 ,\n",
       "         6.99735901,  5.52591403]),\n",
       " array([25.63594541, 20.24507104, 15.98782081, 12.6258097 ,  9.97078166,\n",
       "         7.87406822,  6.21826377,  4.91065142]),\n",
       " array([28.84791001, 22.78160521, 17.99095796, 14.20771562, 11.22003529,\n",
       "         8.8606216 ,  6.99735901,  5.52591403,  4.36389298]),\n",
       " array([32.46230628, 25.63594541, 20.24507104, 15.98782081, 12.6258097 ,\n",
       "         9.97078166,  7.87406822,  6.21826377,  4.91065142,  3.87801134]),\n",
       " array([36.52955549, 28.84791001, 22.78160521, 17.99095796, 14.20771562,\n",
       "        11.22003529,  8.8606216 ,  6.99735901,  5.52591403,  4.36389298,\n",
       "         3.44622841])]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rawbintree(S, u, d, n, t, r, ex_div):\n",
    "    '''\n",
    "    Binomial tree with dividend adjustment\n",
    "    returns a list containing the binomial tree\n",
    "    \n",
    "    S: Stock Price\n",
    "    u: np.exp(sigma * np.sqrt(t))\n",
    "    d: 1.0 / u\n",
    "    n: Steps of Binomial Tree\n",
    "    t: Time to maturity (days) per steps\n",
    "    ex_div: Dividends, which are given in the format np.array([[time_to_ExDate, ExDate_to_Maturity, dividend]])\n",
    "    I assume each of steps of the binomial tree evenly spreads out the time to maturity for this option\n",
    "    '''   \n",
    "#     print(\"ex_div\", ex_div)\n",
    "    # Creating a binomial tree with dividends adjustment\n",
    "    time_to_ex = ex_div[0, 0]\n",
    "    ex_to_mat = ex_div[0, 1]\n",
    "    div = ex_div[0, 2]\n",
    "    \n",
    "    S0 = S - div*np.exp(-r* time_to_ex/n)\n",
    "    \n",
    "    tree = [np.array([S0])]\n",
    "    for i in range(n):\n",
    "        tree.append(np.concatenate((tree[-1][:1]*u, tree[-1]*d))) \n",
    "\n",
    "    return tree\n",
    "\n",
    "rawbintree(S, u, d, n, t, r, div_annual)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae16a228-f0ab-4109-b085-487bdc448ae8",
   "metadata": {},
   "source": [
    "## end of validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cbb8f3-7965-4db5-add3-87a39e6fece0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e70c247a-8a1a-4b8e-badf-8fea7ed9cad9",
   "metadata": {},
   "source": [
    "# Construct tracer options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6f26f84-46db-4510-bdc7-31da20dbe4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime \n",
    "def synthetic(raw_data, target_maturity, df_dividend):\n",
    "    stkid = raw_data['SecurityID'].values[0]\n",
    "    ticker = raw_data['Ticker'].values[0]\n",
    "    \n",
    "    data = raw_data.copy()\n",
    "    data['Date'] = pd.to_datetime(data['Date'])   \n",
    "    data_out = pd.DataFrame(columns=['Date','StockPrice','CallPut','Expiration', 'Maturity', 'Strike', 'OptionPrice', 'IV', 'SecurityID', 'Ticker'])\n",
    "    \n",
    "    for date, df_one in data.groupby('Date'):\n",
    "        S = df_one.S0.values[0]\n",
    "        X = df_one.S0.values[0]\n",
    "        CP = df_one.CallPut.values[0]\n",
    "        T = target_maturity*1.0/252\n",
    "        r = df_one.TargetRate.values[0]\n",
    "        \n",
    "        IV_0 = df_one.IV0[df_one.IV0>0].mean()\n",
    "        if IV_0 < 0:\n",
    "            dt_a = 0\n",
    "            while IV_0 < 0:\n",
    "                dt_a = dt_a + 1\n",
    "                IV_0=data.IV0[data.Date==(date - datetime.timedelta(dt_a))].mean()\n",
    "        if IV_0 < 0:\n",
    "            IV_0 = 1.5\n",
    "        if np.isnan(IV_0):\n",
    "            IV_0 = 1.5        \n",
    "        expiration = date + datetime.timedelta(days=target_maturity)\n",
    "        \n",
    "        \n",
    "        dividends = df_dividend.loc[df_dividend['DistributionType'] == 1, ['ExDate', 'Amount', 'DeclareDate']]\n",
    "        dividends = dividends.reset_index(drop = True)\n",
    "        \n",
    "        if len(dividends) > 0:\n",
    "            ### determine whether today (the date of this observation) is between the decalare date and ex date\n",
    "            div_idx = []\n",
    "            for j in dividends.index:\n",
    "                if (dividends.loc[j, 'DeclareDate'] < date) & (date < dividends.loc[j, 'ExDate']):\n",
    "                    div_idx.append(j)\n",
    "            dividends = dividends.loc[div_idx, :]\n",
    "\n",
    "            if len(dividends) > 0:\n",
    "                expir_date = np.unique(date + pd.DateOffset(days = target_maturity))[0]\n",
    "                time_to_ExDate = np.array([(t-date).days / 252 for t in dividends.ExDate])                        # time to Ex date (annualized divided by 252 days per year)\n",
    "                ExDate_to_Maturity = np.array([(expir_date-t).days / 252 for t in dividends.ExDate])              # Ex date to Maturity date (annualized divided by 252 days per year)\n",
    "                div_annual = np.array([time_to_ExDate, ExDate_to_Maturity, dividends.Amount]).T                   # Dividend table with maturity of Ex date\n",
    "\n",
    "                div_annual = div_annual[(div_annual[:,0]>0) & (div_annual[:,1]>0)]\n",
    "            else:\n",
    "                div_annual = np.array([[1, 1, 0.0]])\n",
    "        else:\n",
    "            div_annual = np.array([[1, 1, 0.0]])        \n",
    "        \n",
    "        # try:\n",
    "        if len(df_one) == 1:\n",
    "            MBBO_synthetic = df_one.V0.values[0]\n",
    "            iv_interpolate = df_one.IV0.values[0]\n",
    "            iv_bin = df_one.IV0.values[0] \n",
    "            if np.isnan(iv_bin) == True:\n",
    "                def f(x):\n",
    "                    return (AM(ft.partial(invalue_func, K=X, CallPut=CP),S, T, r, x, 500, div_annual)-MBBO_synthetic)**2\n",
    "\n",
    "                cons = ({'type': 'ineq', 'fun' : lambda x: np.array(x), 'jac': lambda x: np.array([1.0])})\n",
    "                res = minimize(f,IV_0,constraints=cons,tol = 0.01)\n",
    "                iv_bin = float(res.x)\n",
    "                if np.isnan(iv_bin) == True:        \n",
    "                    print(date, ' IV from binominal tree is nan, please check')                \n",
    "        else:\n",
    "            if (np.abs(S/X-1) < 0.01) and (target_maturity in df_one.Maturity.values):\n",
    "                # print(date,1)\n",
    "                MBBO_synthetic = float(df_one.loc[(target_maturity == df_one.Maturity), 'V0'].values[0])\n",
    "                iv_interpolate = float(df_one.loc[(target_maturity == df_one.Maturity), 'IV0'].values[0])\n",
    "            elif (target_maturity in df_one.Maturity.values) | (len(np.unique(df_one.Maturity.values)) == 1):\n",
    "                # print(date,2)\n",
    "                try:\n",
    "                    spline = sp.interpolate.interp1d(df_one.K.values, df_one.V0.values)\n",
    "                    MBBO_synthetic = float(spline(X))\n",
    "                    spline2 = sp.interpolate.interp1d(df_one.K.values, df_one.IV0.values)\n",
    "                    iv_interpolate = float(spline2(X))\n",
    "                except:\n",
    "                    MBBO_synthetic = np.mean(df_one.V0.values)\n",
    "                    iv_interpolate = np.mean(df_one.IV0.values)\n",
    "                    print(date)\n",
    "                    print(df_one)\n",
    "            elif np.abs(S/X-1) < 0.01:\n",
    "                # print(date,3)\n",
    "                data_2d = df_one.copy()\n",
    "                try:\n",
    "                    spline = sp.interpolate.interp1d(data_2d.Maturity.values, data_2d.V0.values, fill_value=\"extrapolate\")\n",
    "                    MBBO_synthetic = float(spline(target_maturity))\n",
    "                    spline2 = sp.interpolate.interp1d(data_2d.Maturity.values, data_2d.IV0.values, fill_value=\"extrapolate\")\n",
    "                    iv_interpolate = float(spline2(target_maturity))\n",
    "                except:\n",
    "                    MBBO_synthetic = np.mean(df_one.V0.values)\n",
    "                    iv_interpolate = np.mean(df_one.IV0.values)\n",
    "                    print(date)\n",
    "                    print(df_one)                    \n",
    "            else:\n",
    "                # print(date,4)\n",
    "                try:\n",
    "                    spline = sp.interpolate.interp2d(df_one.Maturity.values, df_one.K.values, df_one.V0.values, fill_value=\"extrapolate\")\n",
    "                    MBBO_synthetic = float(spline(target_maturity, X))\n",
    "                    spline2 = sp.interpolate.interp2d(df_one.Maturity.values, df_one.K.values, df_one.IV0.values, fill_value=\"extrapolate\")\n",
    "                    iv_interpolate = float(spline2(target_maturity, X))\n",
    "                except:\n",
    "                    MBBO_synthetic = np.mean(df_one.V0.values)\n",
    "                    iv_interpolate = np.mean(df_one.IV0.values)\n",
    "                    print(date)\n",
    "                    print(df_one)                      \n",
    "\n",
    "            def f(x):\n",
    "                return (AM(ft.partial(invalue_func, K=X, CallPut=CP),S, T, r, x, 500, div_annual)-MBBO_synthetic)**2\n",
    "            cons = ({'type': 'ineq', 'fun' : lambda x: x-0.1, 'jac': lambda x: 1.0})\n",
    "            res = minimize(f, IV_0, constraints=cons,tol = 0.01)\n",
    "            iv_bin = float(res.x)\n",
    "            \n",
    "            if np.isnan(iv_bin):\n",
    "                print(date, ' IV from binominal tree is nan, please check')\n",
    "            \n",
    "        s = pd.Series([date, S, CP, expiration, target_maturity, X, MBBO_synthetic, iv_bin, iv_interpolate, stkid, ticker],\n",
    "                      index=['Date','StockPrice', 'CallPut', 'Expiration', 'Maturity', 'Strike', 'OptionPrice', 'IV', 'IV_interp', 'SecurityID', 'Ticker'])\n",
    "        data_out = data_out.append(s,ignore_index=True)\n",
    "        \n",
    "    return data_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45763b5e-fb76-49f3-8043-beb9cc4fb8f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_84721/3275971170.py:29: RuntimeWarning: overflow encountered in multiply\n",
      "  tree.append(np.concatenate((tree[-1][:1]*u, tree[-1]*d)))\n",
      "/tmp/ipykernel_84721/3275971170.py:29: RuntimeWarning: overflow encountered in multiply\n",
      "  tree.append(np.concatenate((tree[-1][:1]*u, tree[-1]*d)))\n",
      "/tmp/ipykernel_84721/3275971170.py:29: RuntimeWarning: overflow encountered in multiply\n",
      "  tree.append(np.concatenate((tree[-1][:1]*u, tree[-1]*d)))\n",
      "/tmp/ipykernel_84721/3275971170.py:29: RuntimeWarning: overflow encountered in multiply\n",
      "  tree.append(np.concatenate((tree[-1][:1]*u, tree[-1]*d)))\n",
      "/tmp/ipykernel_84721/3275971170.py:29: RuntimeWarning: overflow encountered in multiply\n",
      "  tree.append(np.concatenate((tree[-1][:1]*u, tree[-1]*d)))\n",
      "/tmp/ipykernel_84721/3275971170.py:29: RuntimeWarning: overflow encountered in multiply\n",
      "  tree.append(np.concatenate((tree[-1][:1]*u, tree[-1]*d)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating synthetic 113993\n",
      "CPU times: user 3min 37s, sys: 844 ms, total: 3min 37s\n",
      "Wall time: 3min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "output_path = workdir + 'data/processed/synthetic/'\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "if os.path.exists(output_path + 'df_' + str(stkid) + '.csv') == True:\n",
    "    print('Synthetic '+ str(stkid) + ' exists already')        \n",
    "else:\n",
    "    # read and clean option data\n",
    "    df_dividend.rename(columns = {'amount': 'Amount'}, inplace = True)\n",
    "    if len(df_option)<2:\n",
    "        print('Options of '+ str(stkid) + ' are not available')        \n",
    "    else:\n",
    "        df_syn_call = pd.DataFrame()\n",
    "        df_syn_put = pd.DataFrame()\n",
    "        for target in [30, 60, 90]:\n",
    "            df_ATM_C = get_closest_ATM_option(df_stock, df_rate, df_raw = df_option, optype = 'C', target_maturity = target, stkid = stkid, ticker = ticker)\n",
    "            df_ATM_P = get_closest_ATM_option(df_stock, df_rate, df_raw = df_option, optype = 'P', target_maturity = target, stkid = stkid, ticker = ticker)\n",
    "            if (len(df_ATM_C) > 0) & (len(df_ATM_P) > 0):\n",
    "                syn_call = synthetic(raw_data = df_ATM_C, target_maturity = target, df_dividend = df_dividend)\n",
    "                df_syn_call = pd.concat([df_syn_call, syn_call])\n",
    "\n",
    "                syn_put = synthetic(raw_data = df_ATM_P, target_maturity = target, df_dividend = df_dividend)\n",
    "                df_syn_put = pd.concat([df_syn_put, syn_put])\n",
    "            else:\n",
    "                print('Options of '+ str(stkid) + ' ATM ' + str(target) + ' days are not available') \n",
    "\n",
    "        print('Creating synthetic '+ str(stkid))\n",
    "        df_out =  pd.concat([df_syn_call, df_syn_put])\n",
    "        df_out.to_csv(output_path + 'df_' + str(stkid) + '.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36ef5f8-98c4-4c6e-bbc7-d9a1fc200863",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "10b6f283-6761-484a-a7e0-1a63d8b397ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>K</th>\n",
       "      <th>Expiration</th>\n",
       "      <th>CallPut</th>\n",
       "      <th>BestBid</th>\n",
       "      <th>BestOffer</th>\n",
       "      <th>LastTradeDate</th>\n",
       "      <th>Volume</th>\n",
       "      <th>IV0</th>\n",
       "      <th>Delta</th>\n",
       "      <th>Gamma</th>\n",
       "      <th>Vega</th>\n",
       "      <th>Theta</th>\n",
       "      <th>OptionID</th>\n",
       "      <th>V0</th>\n",
       "      <th>Maturity</th>\n",
       "      <th>tau</th>\n",
       "      <th>S0</th>\n",
       "      <th>AdjClosePrice</th>\n",
       "      <th>AdjClosePrice2</th>\n",
       "      <th>AdjustmentFactor</th>\n",
       "      <th>AdjustmentFactor2</th>\n",
       "      <th>M0</th>\n",
       "      <th>short_rate</th>\n",
       "      <th>r</th>\n",
       "      <th>TargetMaturity</th>\n",
       "      <th>Days</th>\n",
       "      <th>TargetRate</th>\n",
       "      <th>diff</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>SecurityID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>C</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.01</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.577644</td>\n",
       "      <td>0.531779</td>\n",
       "      <td>0.188242</td>\n",
       "      <td>1.453972</td>\n",
       "      <td>-5.438848</td>\n",
       "      <td>127079613</td>\n",
       "      <td>0.840</td>\n",
       "      <td>29</td>\n",
       "      <td>0.080556</td>\n",
       "      <td>12.97</td>\n",
       "      <td>12.97</td>\n",
       "      <td>12.534994</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.877128</td>\n",
       "      <td>0.997692</td>\n",
       "      <td>0.024459</td>\n",
       "      <td>0.025720</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>0.025784</td>\n",
       "      <td>-1</td>\n",
       "      <td>GME</td>\n",
       "      <td>113993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2019-02-08</td>\n",
       "      <td>C</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.39</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.612206</td>\n",
       "      <td>0.538836</td>\n",
       "      <td>0.159162</td>\n",
       "      <td>1.617428</td>\n",
       "      <td>-5.174283</td>\n",
       "      <td>127317757</td>\n",
       "      <td>0.995</td>\n",
       "      <td>36</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>12.97</td>\n",
       "      <td>12.97</td>\n",
       "      <td>12.534994</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.877128</td>\n",
       "      <td>0.997692</td>\n",
       "      <td>0.024459</td>\n",
       "      <td>0.026163</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>0.025784</td>\n",
       "      <td>6</td>\n",
       "      <td>GME</td>\n",
       "      <td>113993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date     K Expiration CallPut  BestBid  BestOffer LastTradeDate  \\\n",
       "1 2019-01-03  13.0 2019-02-01       C     0.67       1.01    2019-01-02   \n",
       "2 2019-01-03  13.0 2019-02-08       C     0.60       1.39           NaT   \n",
       "\n",
       "   Volume       IV0     Delta     Gamma      Vega     Theta   OptionID     V0  \\\n",
       "1     0.0  0.577644  0.531779  0.188242  1.453972 -5.438848  127079613  0.840   \n",
       "2     0.0  0.612206  0.538836  0.159162  1.617428 -5.174283  127317757  0.995   \n",
       "\n",
       "   Maturity       tau     S0  AdjClosePrice  AdjClosePrice2  AdjustmentFactor  \\\n",
       "1        29  0.080556  12.97          12.97       12.534994               2.0   \n",
       "2        36  0.100000  12.97          12.97       12.534994               2.0   \n",
       "\n",
       "   AdjustmentFactor2        M0  short_rate         r  TargetMaturity  Days  \\\n",
       "1           2.877128  0.997692    0.024459  0.025720              30    30   \n",
       "2           2.877128  0.997692    0.024459  0.026163              30    30   \n",
       "\n",
       "   TargetRate  diff Ticker  SecurityID  \n",
       "1    0.025784    -1    GME      113993  \n",
       "2    0.025784     6    GME      113993  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ATM_C.loc[df_ATM_C['S0'] == 12.97, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af0b4f4-db47-4f2f-981a-c0a62a569449",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e645bfd-a8d9-4b91-9d17-0a98742cf175",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3d0d75-47d0-4e26-b61a-354efb6536e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57d31c9f-5b09-4400-a0a4-c0a11ed00d60",
   "metadata": {},
   "source": [
    "# Calculate implied dividend rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc950f8a-f5f9-4ff3-af9d-54dbd25519c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"src/functions_clean.py\"\n",
    "%run \"src/functions_greeks.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d081b850-f58d-48c9-a91d-06bea1ccbb35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic 113993 done\n",
      "CPU times: user 5.19 s, sys: 11.8 ms, total: 5.2 s\n",
      "Wall time: 5.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "input_path = workdir + 'data/processed/synthetic/'\n",
    "output_path = workdir + 'data/cleaned/synthetic/'\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "if os.path.exists(input_path + 'df_' + str(stkid) + '.csv') == False:\n",
    "    print('Synthetic '+ str(stkid) + ' is not available')        \n",
    "elif os.path.exists(output_path + 'df_' + str(stkid) + '.csv') == True:\n",
    "    print('Synthetic '+ str(stkid) + ' exists already')        \n",
    "elif os.stat(input_path + 'df_' + str(stkid) + '.csv').st_size < 2:\n",
    "    print('Synthetic '+ str(stkid) + ' is not available')        \n",
    "else:  \n",
    "    df_ATM = pd.read_csv(input_path + 'df_' + str(stkid) + '.csv', parse_dates = ['Date', 'Expiration'])\n",
    "    df_ATM = df_ATM.rename(columns = {'Strike': 'K', 'StockPrice': 'S0', 'IV': 'IV0', 'OptionPrice': 'V0'})\n",
    "    df_ATM = merge_interest(df_ATM, df_rate)\n",
    "\n",
    "    ## calculate implied dividend\n",
    "    df_ATM_d = calc_syn_implied_div(stkid, df_ATM)\n",
    "    df_syn = pd.DataFrame()\n",
    "    for (callput, m), group in df_ATM_d.groupby(['CallPut', 'Maturity']):\n",
    "        df_ATM_dtmp = group.loc[(group['Maturity'] == m) & (group['CallPut'] == callput) , :].sort_values('Date')\n",
    "        df_ATM_dtmp['abs_impl_div0'] = np.abs(df_ATM_dtmp['impl_div0']) \n",
    "        df_ATM_dtmp['ma_impl_div0'] = df_ATM_dtmp[['Date', 'impl_div0']].rolling(m).mean()\n",
    "        df_ATM_dtmp['rel_impl_div0'] = df_ATM_dtmp['impl_div0'] / df_ATM_dtmp['ma_impl_div0']    \n",
    "        df_syn = pd.concat([df_syn, df_ATM_dtmp])\n",
    "    df_syn['tau'] = df_syn['Maturity'] / 360.\n",
    "\n",
    "    ## merge real dividend\n",
    "    df_dividend = read_dividend(stkid)\n",
    "    real_div = pd.DataFrame()\n",
    "    for row in df_dividend.index:\n",
    "        sdate = df_dividend.loc[row, 'DeclareDate']\n",
    "        edate = df_dividend.loc[row, 'ExDate']\n",
    "        div = df_dividend.loc[row, 'amount']\n",
    "        real_div_tmp = pd.DataFrame({'Date':pd.date_range(sdate,edate-datetime.timedelta(days=1),freq='d')})\n",
    "        real_div_tmp['real_div0'] = div\n",
    "        real_div = pd.concat([real_div, real_div_tmp])\n",
    "    if real_div.shape[0] == 0:\n",
    "        print('no real dividend')\n",
    "        df_syn['impl_cdiv0'] = 0\n",
    "        df_syn['real_div0'] = 0\n",
    "    else:\n",
    "        df_syn = df_syn.merge(real_div, how = 'left', on = ['Date']) \n",
    "        df_syn['real_div0'] = df_syn['real_div0'].fillna(value=0)\n",
    "\n",
    "    ## greeks:\n",
    "    ## delta\n",
    "    df_syn['delta_bs_impl_cdiv'] = bs_call_delta(vol=df_syn['IV0'], S=df_syn['S0'], K=df_syn['K'], tau=df_syn['tau'], r=df_syn['r'], q=df_syn['impl_cdiv0'])\n",
    "    df_syn['delta_bs_impl_cdiv_P'] = bs_put_delta(vol=df_syn['IV0'], S=df_syn['S0'], K=df_syn['K'], tau=df_syn['tau'], r=df_syn['r'], q=df_syn['impl_cdiv0'])\n",
    "    df_syn.loc[df_syn['CallPut'] == 'P', 'delta_bs_impl_cdiv'] = df_syn.loc[df_syn['CallPut'] == 'P','delta_bs_impl_cdiv_P']\n",
    "    del df_syn['delta_bs_impl_cdiv_P']\n",
    "\n",
    "    df_syn['delta_bs_real_div'] = bs_call_delta(vol=df_syn['IV0'], S=df_syn['S0'], K=df_syn['K'], tau=df_syn['tau'], r=df_syn['r'], q=df_syn['real_div0'])\n",
    "    df_syn['delta_bs_real_div_P'] = bs_put_delta(vol=df_syn['IV0'], S=df_syn['S0'], K=df_syn['K'], tau=df_syn['tau'], r=df_syn['r'], q=df_syn['real_div0'])\n",
    "    df_syn.loc[df_syn['CallPut'] == 'P', 'delta_bs_real_div'] = df_syn.loc[df_syn['CallPut'] == 'P','delta_bs_real_div_P']\n",
    "    del df_syn['delta_bs_real_div_P']\n",
    "\n",
    "    ## gamma\n",
    "    df_syn['gamma_bs_impl_cdiv'] = bs_gamma(vol=df_syn['IV0'], S=df_syn['S0'], K=df_syn['K'], tau=df_syn['tau'], r=df_syn['r'], q=df_syn['impl_cdiv0'])\n",
    "    df_syn['gamma_bs_real_div'] = bs_gamma(vol=df_syn['IV0'], S=df_syn['S0'], K=df_syn['K'], tau=df_syn['tau'], r=df_syn['r'], q=df_syn['real_div0'])\n",
    "\n",
    "    ## vega\n",
    "    df_syn['vega_bs_impl_cdiv'] = bs_vega(vol=df_syn['IV0'], S=df_syn['S0'], K=df_syn['K'], tau=df_syn['tau'], r=df_syn['r'], q=df_syn['impl_cdiv0'])\n",
    "    df_syn['vega_bs_real_div'] = bs_vega(vol=df_syn['IV0'], S=df_syn['S0'], K=df_syn['K'], tau=df_syn['tau'], r=df_syn['r'], q=df_syn['real_div0'])        \n",
    "\n",
    "    df_syn.to_csv(output_path + 'df_' + str(stkid) + '.csv', index = False)\n",
    "    print('Synthetic '+ str(stkid) + ' done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7eebdd-9260-4f78-a9a0-d83f8ae5497d",
   "metadata": {},
   "source": [
    "# preclean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be1d9ef0-9e7f-4a95-9398-8ffe41e93129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************\n",
      "processing 113993\n",
      "************ done *************\n",
      "CPU times: user 13.7 s, sys: 732 ms, total: 14.4 s\n",
      "Wall time: 14.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "output_path = workdir + 'data/processed/intermediate/'\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "print('*********************************************')\n",
    "print('processing '+ str(stkid))        \n",
    "\n",
    "if os.path.exists(output_path + 'df_' + str(stkid) + '.csv') == True:\n",
    "    print('Stock '+ str(stkid) + ' exists already')        \n",
    "if os.path.exists(datadir + str(stkid)) == False:\n",
    "    print('Stock '+ str(stkid) + ' is not available') \n",
    "    problem_stk_list.append(stkid)\n",
    "else:        \n",
    "    df_stock, df_option, df_dividend, df_info = read_data(str(stkid))\n",
    "    if len(df_option) < 2:\n",
    "        print('Stock '+ str(stkid) + ' ' + ticker + ' is not available from OptionMerics')\n",
    "    else:\n",
    "        df = preclean_data(df_option, df_stock, stkid)\n",
    "        df = merge_interest(df, df_rate)\n",
    "        df = prefilter_data(df)\n",
    "        # df_split = df_dividend[(df_dividend['DistributionType'] != 1)]\n",
    "\n",
    "if len(df) < 2:\n",
    "    problem_stk_list.append(stkid)\n",
    "    print('Stock '+ str(stkid) + ' ' + ticker + ' has insufficient observations')     \n",
    "else:     \n",
    "    for paydate in df_dividend.PaymentDate:\n",
    "        df = df[(df['Date'] != paydate)]\n",
    "        df = df[df['Date'] != paydate - BDay(1)]\n",
    "\n",
    "    df['SecurityID'] = stkid\n",
    "    df['StockTicker'] = ticker\n",
    "\n",
    "    # adjust dividend rate\n",
    "    df_div = pd.read_csv(workdir + 'data/cleaned/synthetic/df_' + str(stkid) + '.csv', parse_dates = ['Date'])\n",
    "    df_div30 = df_div.loc[(df_div['Maturity'] == 30) & (df_div['CallPut'] == 'C'), ['Date', 'impl_div0', 'impl_cdiv0']].rename(columns = {'impl_div0': 'impl_div30', 'impl_cdiv0': 'impl_cdiv30'})\n",
    "    df_div60 = df_div.loc[(df_div['Maturity'] == 60) & (df_div['CallPut'] == 'C'), ['Date', 'impl_div0', 'impl_cdiv0']].rename(columns = {'impl_div0': 'impl_div60', 'impl_cdiv0': 'impl_cdiv60'})\n",
    "    df_div90 = df_div.loc[(df_div['Maturity'] == 90) & (df_div['CallPut'] == 'C'), ['Date', 'impl_div0', 'impl_cdiv0']].rename(columns = {'impl_div0': 'impl_div90', 'impl_cdiv0': 'impl_cdiv90'})\n",
    "    df_realdiv = df_div.loc[(df_div['Maturity'] == 90) & (df_div['CallPut'] == 'C'), ['Date', 'real_div0']].rename(columns = {'real_div0': 'real_div'})\n",
    "    df = df.merge(df_div30, how = 'left', on = 'Date')\n",
    "    df = df.merge(df_div60, how = 'left', on = 'Date')\n",
    "    df = df.merge(df_div90, how = 'left', on = 'Date')\n",
    "    df = df.merge(df_realdiv, how = 'left', on = 'Date')\n",
    "    df['real_div_yield'] = df['real_div'] / df['S0']\n",
    "\n",
    "    df.to_csv(output_path + 'df_' + str(stkid) + '.csv', index = False)\n",
    "\n",
    "print('************ done *************')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b7b87b-aba0-45d3-96a9-fb2b851f1a53",
   "metadata": {},
   "source": [
    "# adjusted implied volatility and adjusted delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3776a5b8-31aa-4246-8c3f-44e46dc12c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "%run \"src/functions_greeks.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866234bf-f9c5-4cc8-bba2-abf1158ae8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_path = workdir + 'data/processed/intermediate/'\n",
    "\n",
    "if os.path.exists(output_path + '/iv_' + str(stkid) + '.csv') == True:\n",
    "    print('***************************************')\n",
    "    print('Stock '+ str(stkid) + ' IV has existed already')        \n",
    "if os.path.exists(input_path + \"df_\" + str(stkid) + \".csv\") == False:\n",
    "    print('*****************************')\n",
    "    print('Stock '+ str(stkid) + ' is not available') \n",
    "else:     \n",
    "    df = pd.read_csv(input_path + \"df_\" + str(stkid) + \".csv\", parse_dates = ['Date']) \n",
    "    df['impl_cdiv_median']=df.loc[:,['impl_cdiv30', 'impl_cdiv60', 'impl_cdiv90']].median(axis=1)\n",
    "\n",
    "    print('***************************************')\n",
    "    print('processing '+ str(stkid) + ' with ' + str(len(df)) + ' rows')\n",
    "\n",
    "\n",
    "if len(df) < 2:\n",
    "    print('Stock '+ str(stkid) + ticker + ' has insufficient observations')\n",
    "else:     \n",
    "    ###############################\n",
    "    # Calculate Implied Volatility\n",
    "    ###############################\n",
    "    start_time = time.time()\n",
    "    # dict_IV = {}\n",
    "    Parallel(n_jobs=8, require='sharedmem', verbose=1)(delayed(cal_iv_core)(idx, group) for idx, group in df.groupby(['Date', 'Expiration']))  \n",
    "    print(str(stkid) + ' implied volatility within %s seconds' % (time.time()-start_time))\n",
    "    df_IV_out = pd.DataFrame()\n",
    "    for key, val in dict_IV.items():\n",
    "        df_IV_out = pd.concat([df_IV_out, dict_IV[key]])\n",
    "\n",
    "    df_IV_out.to_csv(output_path + '/iv_' + str(stkid) + '.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dbf4c6-a528-4095-aacc-8f15f9eef372",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(input_path + \"iv_\" + str(stkid) + \".csv\") == False:\n",
    "    print('*****************************')\n",
    "    print('Stock '+ str(stkid) + ' is not available') \n",
    "else:     \n",
    "    df = pd.read_csv(input_path + \"iv_\" + str(stkid) + \".csv\", parse_dates = ['Date']) \n",
    "    print('***************************************')\n",
    "    print('processing '+ str(stkid) + ' with ' + str(len(df)) + ' rows')\n",
    "\n",
    "if len(df) < 2:\n",
    "    print('Stock '+ str(stkid) + ticker + ' has insufficient observations')\n",
    "else:     \n",
    "    ##################\n",
    "    # Calculate Delta\n",
    "    ################## \n",
    "    start_time = time.time()\n",
    "    # dict_delta = {}\n",
    "    Parallel(n_jobs=8, require='sharedmem', verbose=1)(delayed(cal_delta_core)(idx, group) for idx, group in df.groupby(['Date', 'Expiration']))  \n",
    "    print(str(stkid) + ' delta within %s seconds' % (time.time()-start_time))\n",
    "\n",
    "    df_delta_out = pd.DataFrame()\n",
    "    for key, val in dict_delta.items():\n",
    "        df_delta_out = pd.concat([df_delta_out, dict_delta[key]])\n",
    "\n",
    "    df_delta_out['Delta_c'] = (df_delta_out['V_up'] - df_delta_out['V_down']) / (df_delta_out['S0'] * 0.02)\n",
    "    df_delta_out.to_csv(output_path + '/delta_'+ str(stkid) + '.csv', index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfcf193-e5af-4196-9ef1-bdfd75109b71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f95700b-b33f-426e-91fa-670e58c18f00",
   "metadata": {},
   "source": [
    "# rolling regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8333edd4-09f8-4f8b-b25a-a296d7f5c23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_hedge(df_input):\n",
    "    df = df_input.copy()\n",
    "    #----------------------------\n",
    "    # Calculate Hedge PNL/Error\n",
    "    #----------------------------\n",
    "    df['Zero_Hedge_PL'] = df['V0_n']*df['on_ret'] - df['V1_n']\n",
    "    df_C = df[(df['CallPut'] == 'C')]\n",
    "    df_P = df[(df['CallPut'] == 'P')] \n",
    "    NoHedge_C = np.mean(df_C['Zero_Hedge_PL'] ** 2)\n",
    "    NoHedge_P = np.mean(df_P['Zero_Hedge_PL'] ** 2)\n",
    "    return NoHedge_C, NoHedge_P\n",
    "\n",
    "\n",
    "def BS_hedge(df_input, delta_var):\n",
    "    df = df_input.copy()\n",
    "    df['BS_PL'] = df[delta_var] * df['S1_n'] + df['on_ret'] * (df['V0_n'] - df[delta_var] * df['S0_n']) - df['V1_n']\n",
    "    df_C = df[df['CallPut'] == 'C']\n",
    "    df_P = df[df['CallPut'] == 'P']      \n",
    "    BSHedge_C = np.mean(df_C.loc[:,'BS_PL'] ** 2)\n",
    "    BSHedge_P = np.mean(df_P.loc[:,'BS_PL'] ** 2)\n",
    "    return BSHedge_C, BSHedge_P\n",
    "\n",
    "\n",
    "def Fixed_BS_Hedge(df_input, delta_var, call_coef = 0.9, put_coef = 1.1, whole_period = False):\n",
    "    df = df_input.copy()    \n",
    "    df.loc[df['CallPut'] == 'C', 'DeltaFixed'] = call_coef * df[delta_var]\n",
    "    df.loc[df['CallPut'] == 'P', 'DeltaFixed'] = put_coef * df[delta_var]\n",
    "    df['Fixed_PL'] = df['DeltaFixed'] * df['S1_n'] + df['on_ret'] * (df['V0_n'] - df['DeltaFixed'] * df['S0_n']) - df['V1_n']\n",
    "    df_C = df[(df['CallPut'] == 'C')]\n",
    "    df_P = df[(df['CallPut'] == 'P')]\n",
    "    \n",
    "    FixedHedge_C = np.mean(df_C['Fixed_PL']** 2)\n",
    "    FixedHedge_P = np.mean(df_P['Fixed_PL'] ** 2)\n",
    "\n",
    "    return FixedHedge_C, FixedHedge_P\n",
    "\n",
    "\n",
    "def calc_pnl(train, test, weight, delta_var = 'Delta'): \n",
    "    df_train = train.copy()\n",
    "    df_test = test.copy()\n",
    "    df_weight = weight.copy()\n",
    "    \n",
    "    delta_hat = pd.Series(index=df_test.index, dtype = 'float64')\n",
    "    dict_output = {}\n",
    "    dict_plot = {}\n",
    "    \n",
    "    if len(np.unique(df_train['CallPut'])) == 1:\n",
    "        if np.unique(df_train['CallPut'])[0] == 'C':\n",
    "            df_train.loc[-1, 'CallPut'] = 'P'\n",
    "        else:\n",
    "            df_train.loc[-1, 'CallPut'] = 'C'\n",
    "    \n",
    "    for optype, group in df_train.groupby(by=['CallPut']):\n",
    "        test_index = df_test.loc[df_test['CallPut'] == optype].index\n",
    "        dict_coef = {}        \n",
    "        if len(group) < 2:\n",
    "            print('training set of ' + optype + ' has insufficient observations')\n",
    "            coef = [np.nan]\n",
    "            std = np.nan\n",
    "            pass\n",
    "        else:\n",
    "            ## add weights\n",
    "            group = pd.merge(group, df_weight, how = 'left', on = 'Date')\n",
    "            earliest = group.loc[group['Date'] == np.min(group['Date'].values), :].copy()\n",
    "             \n",
    "            ## y_train is the change of option price in the training set\n",
    "            y_train = group['V1_n'] - group['V0_n'] * group['on_ret']\n",
    "            ## x_train is Delta times the change of stock price in the training set\n",
    "            w_train = group.loc[:, 'weight'].copy()\n",
    "            x_train = group.loc[:, delta_var].copy()\n",
    "            x_train = x_train.multiply(group['S1_n'] - group['S0_n'] * group['on_ret'], axis=0).values.reshape(-1,1)\n",
    "            lin = LinearRegression(fit_intercept=False).fit(x_train, y_train, sample_weight = group['weight'])\n",
    "            coef = lin.coef_\n",
    "            \n",
    "            y_earliest = earliest['V1_n'] - earliest['V0_n'] * earliest['on_ret']\n",
    "            x_earliest = earliest.loc[:, delta_var].copy()\n",
    "            x_earliest = x_earliest.multiply(earliest['S1_n'] - earliest['S0_n'] * earliest['on_ret'], axis=0).values.reshape(-1,1)\n",
    "            w_earliest = earliest.loc[:, 'weight'].copy()\n",
    "            \n",
    "            dict_plot[optype + '_x_train'] = x_train\n",
    "            dict_plot[optype + '_y_train'] = y_train\n",
    "            dict_plot[optype + '_w_train'] = w_train\n",
    "            dict_plot[optype + '_coef'] = coef\n",
    "            dict_plot[optype + '_x_earliest'] = x_earliest\n",
    "            dict_plot[optype + '_y_earliest'] = y_earliest\n",
    "            dict_plot[optype + '_w_earliest'] = w_earliest\n",
    "            \n",
    "            ## calculate the standard error of coefficient\n",
    "            y_hat_train = lin.predict(x_train)\n",
    "            residual_sum_of_square = ((y_train - y_hat_train) ** 2).sum()\n",
    "            sigma_square_hat = residual_sum_of_square / (x_train.shape[0] - x_train.shape[1])\n",
    "            var_beta = (np.linalg.inv(x_train.T @ x_train) * sigma_square_hat)\n",
    "            std = [np.sqrt(var_beta[i, i]) for i in range(len(var_beta))]\n",
    "            \n",
    "            \n",
    "            ## y_hat_test is predicted delta in the test set \n",
    "            if len(df_test[(df_test['CallPut'] == optype)]) < 1:\n",
    "                print('test set of ' + optype + ' has insufficient observations')\n",
    "                pass\n",
    "            else:\n",
    "                delta_hat.loc[test_index] = lin.predict(df_test.loc[test_index, delta_var].values.reshape(-1,1))\n",
    "                \n",
    "                y_test = df_test.loc[test_index, 'V1_n'] - df_test.loc[test_index, 'V0_n'] * df_test.loc[test_index, 'on_ret']\n",
    "                x_test = df_test.loc[test_index, delta_var].copy()\n",
    "                x_test = x_test.multiply(df_test.loc[test_index, 'S1_n'] - df_test.loc[test_index, 'S0_n'] * df_test.loc[test_index, 'on_ret'], axis=0).values.reshape(-1,1)  \n",
    "\n",
    "                dict_plot[optype + '_x_test'] = x_test\n",
    "                dict_plot[optype + '_y_test'] = y_test\n",
    "                dict_plot[optype + '_predict'] = lin.predict(x_test)   \n",
    "            \n",
    "        dict_coef['type'] = optype\n",
    "        dict_coef['coef'] = coef\n",
    "        dict_coef['std'] = std\n",
    "        dict_coef['N_train'] = len(group)\n",
    "        dict_coef['days_train'] = len(np.unique(group.Date))\n",
    "        dict_coef['N_test'] = len(df_test.loc[test_index])\n",
    "        dict_coef['days_test'] = len(np.unique(df_test.loc[test_index].Date))\n",
    "                \n",
    "        df_test_atm = df_test.loc[(df_test['CallPut'] == optype), :]\n",
    "        if len(df_test_atm) == 0:\n",
    "            atm30_vol = np.NaN\n",
    "            atm30_v = np.NaN\n",
    "            atm60_vol = np.NaN\n",
    "            atm60_v = np.NaN\n",
    "            atm90_vol = np.NaN\n",
    "            atm90_v = np.NaN\n",
    "            pass\n",
    "        else:\n",
    "            atm30_vol = np.unique(df_test_atm.loc[:, 'IV_ATM30'])[0]\n",
    "            atm30_v = np.unique(df_test_atm.loc[:, 'V_ATM30'])[0]\n",
    "            if (atm30_vol < 0.01) | (atm30_vol > 5):\n",
    "                atm30_vol = np.NaN\n",
    "            atm60_vol = np.unique(df_test_atm.loc[:, 'IV_ATM60'])[0]\n",
    "            atm60_v = np.unique(df_test_atm.loc[:, 'V_ATM60'])[0]\n",
    "            if (atm60_vol < 0.01) | (atm60_vol > 5):\n",
    "                atm60_vol = np.NaN\n",
    "            atm90_vol = np.unique(df_test_atm.loc[:, 'IV_ATM90'])[0]\n",
    "            atm90_v = np.unique(df_test_atm.loc[:, 'V_ATM90'])[0]\n",
    "            if (atm60_vol < 0.01) | (atm60_vol > 5):\n",
    "                atm90_vol = np.NaN\n",
    "       \n",
    "        dict_coef['atm30_vol_test'] = atm30_vol\n",
    "        dict_coef['atm30_oprice_test'] = atm30_v\n",
    "        dict_coef['atm60_vol_test'] = atm60_vol\n",
    "        dict_coef['atm60_oprice_test'] = atm60_v        \n",
    "        dict_coef['atm90_vol_test'] = atm90_vol\n",
    "        dict_coef['atm90_oprice_test'] = atm90_v \n",
    "               \n",
    "        dict_coef['list_maturity_train'] = np.unique(group.Maturity)\n",
    "        dict_output[optype] = dict_coef\n",
    "\n",
    "    #------------------------------------------\n",
    "    ## calculate PNL using the estimated delta\n",
    "    #------------------------------------------\n",
    "    pnl = delta_hat * df_test['S1_n'] + (df_test['V0_n'] - delta_hat * df_test['S0_n']) * df_test['on_ret']  - df_test['V1_n']  \n",
    "\n",
    "    df_PNL = df_test[['Date', 'CallPut']].copy()\n",
    "    df_PNL['delta'] = delta_hat\n",
    "    df_PNL['PNL'] = pnl\n",
    "    df_PNL['M0'] = df_test['M0'].copy()\n",
    "    df_PNL['tau0'] = df_test['tau0'].copy()\n",
    "    df_PNL['OptionID'] = df_test['OptionID'].copy()\n",
    "    return df_PNL, dict_output, dict_plot, group\n",
    "\n",
    "def merge_syn(df_input, stock_id):\n",
    "    df = df_input.copy()\n",
    "    df_syn = pd.read_csv(workdir + 'data/processed/synthetic/df_' + str(stock_id) + '.csv', parse_dates = ['Date', 'Expiration'])\n",
    "    df_syn_30 = df_syn.loc[df_syn['Maturity'] == 30, ['Date', 'CallPut', 'StockPrice', 'OptionPrice', 'IV']].rename(columns = {'IV': 'IV_ATM30', 'OptionPrice': 'V_ATM30'})\n",
    "    df_syn_60 = df_syn.loc[df_syn['Maturity'] == 60, ['Date', 'CallPut', 'OptionPrice', 'IV']].rename(columns = {'IV': 'IV_ATM60', 'OptionPrice': 'V_ATM60'})\n",
    "    df_syn_90 = df_syn.loc[df_syn['Maturity'] == 90, ['Date', 'CallPut', 'OptionPrice', 'IV']].rename(columns = {'IV': 'IV_ATM90', 'OptionPrice': 'V_ATM90'})\n",
    "\n",
    "    df_syn = pd.merge(df_syn_30, df_syn_60, on = ['Date', 'CallPut'], how = 'left')\n",
    "    df_syn = df_syn.merge(df_syn_90, on = ['Date', 'CallPut'], how = 'left')\n",
    "\n",
    "    df = df.merge(df_syn, how = 'left', on = ['Date', 'CallPut'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13b1f27-b70e-44d0-885e-e5d919cb7b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 1\n",
    "step_path = '/step_' + str(step) + 'd_'\n",
    "\n",
    "adjusted_delta = 1\n",
    "if adjusted_delta == 1:\n",
    "    adjusted_delta_path = 'adjusted_delta_'\n",
    "    input_path = workdir + 'data/processed/intermediate/' + 'delta_'\n",
    "    delta_var = 'Delta_c'\n",
    "elif adjusted_delta == 0:\n",
    "    adjusted_delta_path = 'raw_delta_'\n",
    "    input_path = workdir + 'data/processed/intermediate/' + 'df_'\n",
    "    delta_var = 'Delta'\n",
    "else:\n",
    "    print('Set the correct delta')\n",
    "\n",
    "    \n",
    "rolling_weights = True\n",
    "\n",
    "M_min = 0\n",
    "M_max = 100\n",
    "train_length = 20 # ([train_length, parameter]: [240, 0.99], [360, 0.995])\n",
    "\n",
    "if rolling_weights:\n",
    "    train_length_path = 'train_length_' + str(train_length) + 'd_wt/'\n",
    "    wt_exp = [0.99**i for i in range(train_length-1, -1, -1)]\n",
    "else:\n",
    "    train_length_path = 'train_length_' + str(train_length) + 'd/'\n",
    "    wt_exp  = [1.00**i for i in range(train_length-1, -1, -1)]\n",
    "\n",
    "output_path = workdir + 'output/regression/moneyness_' + str(M_min) + '_' + str(M_max) + step_path + adjusted_delta_path + train_length_path\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "    os.makedirs(output_path + 'coef')\n",
    "    os.makedirs(output_path + 'MSHE')\n",
    "    os.makedirs(output_path + 'coefplot')\n",
    "    os.makedirs(output_path + 'PNL')\n",
    "    os.makedirs(output_path + 'PNL_plot')\n",
    "    os.makedirs(output_path + 'scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1350d4aa-da8b-4ff6-95fc-47bf1ed49e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter(dict_plot_one, securityid, date_in, output_path, version = adjusted_delta):\n",
    "    if version == 0:\n",
    "        greek_letter = 'Raw Delta'\n",
    "    else:\n",
    "        greek_letter = 'Adjusted Delta'\n",
    "\n",
    "    plt.rc('font', size=25)          # controls default text sizes\n",
    "    datestr = pd.to_datetime(date_in[0]).strftime('%Y-%m-%d')\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(18,9), sharex=True, sharey=True)\n",
    "    # fig.suptitle(tickername + ' ' + str(i) + ' ' + ids[i].strip() + ' ' + datestr)\n",
    "    plt.setp(axs[:], xlabel=greek_letter + \" X Change of Stock Price\")\n",
    "    plt.setp(axs[0], ylabel=\"Change of Option Price\")\n",
    "    \n",
    "    w_C = dict_plot_one['C_w_train'] * 30\n",
    "    w_e_C = dict_plot_one['C_w_earliest'] * 30\n",
    "    axs[0].scatter(dict_plot_one['C_x_train'], dict_plot_one['C_y_train'], s = w_C)\n",
    "    axs[0].plot(dict_plot_one['C_x_train'], dict_plot_one['C_coef'] * dict_plot_one['C_x_train'], color='tab:orange')\n",
    "    axs[0].scatter(dict_plot_one['C_x_test'], dict_plot_one['C_y_test'], color='tab:red')\n",
    "    axs[0].scatter(dict_plot_one['C_x_earliest'], dict_plot_one['C_y_earliest'], s = w_e_C, color='tab:grey')\n",
    "    axs[0].annotate('Call Coefficient: ' + str(round(dict_plot_one['C_coef'][0], 4)), \n",
    "                    xy=(0, 1), xytext=(12, -12), va='top', xycoords='axes fraction', textcoords='offset points')\n",
    "    axs[0].set_title(\"Call\")\n",
    "    \n",
    "    w_P = dict_plot_one['P_w_train'] * 30\n",
    "    w_e_P = dict_plot_one['P_w_earliest'] * 30\n",
    "    axs[1].scatter(dict_plot_one['P_x_train'], dict_plot_one['P_y_train'], s = w_P)\n",
    "    axs[1].plot(dict_plot_one['P_x_train'], dict_plot_one['P_coef'] * dict_plot_one['P_x_train'], color='tab:orange')\n",
    "    axs[1].scatter(dict_plot_one['P_x_test'], dict_plot_one['P_y_test'], color='tab:red')\n",
    "    axs[1].scatter(dict_plot_one['P_x_earliest'], dict_plot_one['P_y_earliest'], s = w_e_P, color='tab:grey')\n",
    "    axs[1].annotate('Put Coefficient: ' + str(round(dict_plot_one['P_coef'][0], 4)), \n",
    "                    xy=(0, 1), xytext=(12, -12), va='top', xycoords='axes fraction', textcoords='offset points')\n",
    "    axs[1].set_title(\"Put\")   \n",
    "    fig.tight_layout()        \n",
    "\n",
    "\n",
    "    scatter_output_path = output_path + 'scatter/' + str(securityid) + '/'\n",
    "    if not os.path.exists(scatter_output_path):\n",
    "        os.makedirs(scatter_output_path)\n",
    "    plt.savefig(scatter_output_path + str(securityid) + '_' + tickername + '_' + datestr + '.jpg')\n",
    "        \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a937826-d7c8-4504-a5ff-c0dfb7d08b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "df_MSHE_all = pd.DataFrame()\n",
    "for i in [100]: # range(100, 119, 1): #{113993: 'Game Stop', 189943: 'AMC'}:  # {107899: 'NASDAQ 100 TR', 102480: 'NASDAQ 100 INDEX', 108105: 'SPX'}: #ids: # {111020: '3Com', 108005: 'NetBank', 111860: 'Walmart'}: \n",
    "    securityid = df_stock_list.loc[i, 'SecurityID']\n",
    "    i = securityid\n",
    "    tickername = df_stock_list.loc[df_stock_list['SecurityID'] == securityid, 'Ticker'].values[0].strip()\n",
    "    j = j + 1\n",
    "    print('*********************************************')\n",
    "    print('No.' + str(j) + ' processing '+ str(i))     \n",
    "    \n",
    "    if os.path.exists(input_path + str(i) + '.csv') == False:\n",
    "        print('Stock '+ str(i) + ' is not available')\n",
    "        continue\n",
    "    else:\n",
    "        temp = pd.read_csv(input_path + str(i) + \".csv\", parse_dates = ['Date'])\n",
    "        # temp = temp.loc[temp['Date'] != pd.to_datetime(\"1998-10-12\"), :]\n",
    "        temp = temp.loc[~temp['IV0'].isna(), :]\n",
    "        #------------------\n",
    "        # Shrink moneyness\n",
    "        #------------------\n",
    "        bl = (temp['M0'] >= M_min-0.001) & (temp['M0'] <= M_max+0.001)\n",
    "        temp = temp.loc[bl] \n",
    "\n",
    "        #---------------------\n",
    "        # more cleaning\n",
    "        #---------------------\n",
    "        # continuous version rate:\n",
    "        temp['on_ret'] = np.exp(temp['short_rate'] * 1 / 253)\n",
    "        \n",
    "        bl_C = ((temp['CallPut'] == 'C') & (temp['Delta_c'] < 10) & (temp['Delta_c'] > 0.01))\n",
    "        bl_P = (temp['CallPut'] == 'P') & (temp['Delta_c'] > -10) & (temp['Delta_c'] < -0.01)\n",
    "        temp = temp[bl_C | bl_P]\n",
    "        \n",
    "        temp = merge_syn(temp, securityid)\n",
    "        ############# Calculating result using pre-bubble data ####################\n",
    "        df_MSHE = pd.DataFrame()\n",
    "        exist_coef = os.path.exists(output_path + 'coef/coef_' + str(i) + '.csv')\n",
    "        exist_mshe = os.path.exists(output_path + 'MSHE/MSHE_' + str(i) + '.csv')\n",
    "        \n",
    "        if (exist_coef == True) & (exist_mshe == True):\n",
    "            print('Stock '+ str(i) + ' MSHE result has existed already')        \n",
    "            pass          \n",
    "        else:\n",
    "            df_PNL = pd.DataFrame()\n",
    "            dict_output = {} \n",
    "            \n",
    "            all_date = np.unique(temp.loc[:, 'Date'])\n",
    "            train_date = all_date[0:train_length]\n",
    "            test_date = all_date[train_length:]             \n",
    "            df_test = temp[temp['Date'].isin(test_date)] \n",
    "            if len(test_date) == 0:\n",
    "                print('insufficient observations because length of test date is 0')\n",
    "                continue\n",
    "            if all_date[0] < pd.to_datetime('2020-01-01'):\n",
    "                pre_train_date = [t for t in all_date if t < pd.to_datetime('2020-01-01')] \n",
    "                pre_test_date = [t for t in all_date if (pd.to_datetime('2020-01-01') < t) & (t < test_date[0])] \n",
    "                df_pre_test = temp[temp['Date'].isin(pre_test_date)]       \n",
    "\n",
    "                for s in range(int(np.ceil(len(pre_test_date)/step))):\n",
    "                    if len(pre_test_date) == 0:\n",
    "                        continue                    \n",
    "                    pre_test_date_in = pre_test_date[0:step]\n",
    "                    first_pre_test_date = str(pre_test_date_in[0])[:10]\n",
    "                    df_train_rolling = temp[temp['Date'].isin(pre_train_date)]\n",
    "                    df_test_rolling = temp[temp['Date'].isin(pre_test_date_in)]\n",
    "                    pre_wt_exp = [1.00**i for i in range(len(pre_train_date)-1, -1, -1)]\n",
    "                    df_weight_rolling = pd.DataFrame({'Date':pre_train_date, 'weight':pre_wt_exp})\n",
    "                    \n",
    "                    # print('-------------------------------------------------------------')\n",
    "                    # print('s:', s)\n",
    "                    # print('pre test date:', first_pre_test_date)\n",
    "                    \n",
    "                    df_PNL_one, dict_output_one, dict_plot_one, weights_test = calc_pnl(df_train_rolling, df_test_rolling, df_weight_rolling)\n",
    "                    df_PNL = pd.concat([df_PNL, df_PNL_one])\n",
    "                    dict_output[first_pre_test_date] = dict_output_one\n",
    "\n",
    "                    plot_scatter(dict_plot_one, securityid, date_in = pre_test_date_in, output_path = output_path) \n",
    "                    \n",
    "                    pre_train_date = np.concatenate([pre_train_date, pre_test_date[0:step]])\n",
    "                    pre_test_date = pre_test_date[step:]\n",
    "\n",
    "          \n",
    "            for s in range(int(np.ceil(len(test_date)/step))):\n",
    "                test_date_in = test_date[0:step]\n",
    "                first_test_date = str(test_date_in[0])[:10]\n",
    "                df_train_rolling = temp[temp['Date'].isin(train_date)]\n",
    "                df_test_rolling = temp[temp['Date'].isin(test_date_in)]\n",
    "                df_weight_rolling = pd.DataFrame({'Date':train_date, 'weight':wt_exp})\n",
    "                \n",
    "                # print('test date:', first_test_date)\n",
    "                \n",
    "                df_PNL_one, dict_output_one, dict_plot_one, weights_test = calc_pnl(df_train_rolling, df_test_rolling, df_weight_rolling)\n",
    "                df_PNL = pd.concat([df_PNL, df_PNL_one])\n",
    "                dict_output[first_test_date] = dict_output_one\n",
    "\n",
    "                plot_scatter(dict_plot_one, securityid, date_in = test_date_in, output_path = output_path) \n",
    "                \n",
    "                train_date = np.concatenate([train_date[step:], test_date[0:step]])\n",
    "                test_date = test_date[step:]\n",
    "\n",
    "            if len(df_PNL) == 0:\n",
    "                df_PNL.loc[0, 'CallPut'] = 'C'\n",
    "                df_PNL.loc[0, 'PNL'] = np.nan\n",
    "                df_PNL.loc[1, 'CallPut'] = 'P'\n",
    "                df_PNL.loc[1, 'PNL'] = np.nan \n",
    "            \n",
    "            df_PNL.to_csv(output_path + 'PNL/PNL_' + str(i) + '.csv', index = False)\n",
    "            \n",
    "            df_MSHE.loc[i, \"name\"] = ids[i]\n",
    "            df_MSHE.loc[i, \"bubble_stock\"] = dict_tech_label[i]\n",
    "            df_MSHE.loc[i, \"BS_hedge_C\"] = BS_hedge(df_test, delta_var)[0]\n",
    "            df_MSHE.loc[i, \"BS_hedge_P\"] = BS_hedge(df_test, delta_var)[1]\n",
    "            df_MSHE.loc[i, \"Fixed_hedge_C\"] = Fixed_BS_Hedge(df_test, delta_var)[0]\n",
    "            df_MSHE.loc[i, \"Fixed_hedge_P\"] = Fixed_BS_Hedge(df_test, delta_var)[1]\n",
    "            df_MSHE.loc[i, \"delta_hedge_C\"] = np.mean(df_PNL[df_PNL['CallPut'] == 'C'].loc[:,'PNL']**2)\n",
    "            df_MSHE.loc[i, \"delta_hedge_P\"] = np.mean(df_PNL[df_PNL['CallPut'] == 'P'].loc[:,'PNL']**2)    \n",
    "            df_MSHE.to_csv(output_path + 'MSHE/MSHE_' + str(i) + '.csv', index = False) \n",
    "            df_MSHE_all = pd.concat([df_MSHE_all, df_MSHE])                     \n",
    "\n",
    "            df_coef_ts = pd.DataFrame()\n",
    "            r = 0\n",
    "            for key in dict_output:\n",
    "                df_coef_ts.loc[r, 'Date_str'] = key\n",
    "                df_coef_ts.loc[r, 'Date'] = pd.to_datetime(key)\n",
    "                df_coef_ts.loc[r, 'coef_C'] = dict_output[key]['C']['coef']\n",
    "                df_coef_ts.loc[r, 'std_C'] = dict_output[key]['C']['std']\n",
    "                df_coef_ts.loc[r, 'N_train_C'] = dict_output[key]['C']['N_train']\n",
    "                df_coef_ts.loc[r, 'days_train_C'] = dict_output[key]['C']['days_train']\n",
    "                df_coef_ts.loc[r, 'N_test_C'] = dict_output[key]['C']['N_test']\n",
    "                df_coef_ts.loc[r, 'atm30_vol_test_C'] = dict_output[key]['C']['atm30_vol_test']\n",
    "                df_coef_ts.loc[r, 'atm60_vol_test_C'] = dict_output[key]['C']['atm60_vol_test']\n",
    "                df_coef_ts.loc[r, 'atm90_vol_test_C'] = dict_output[key]['C']['atm90_vol_test']                \n",
    "                df_coef_ts.loc[r, 'atm30_optice_test_C'] = dict_output[key]['C']['atm30_oprice_test']\n",
    "                df_coef_ts.loc[r, 'atm60_optice_test_C'] = dict_output[key]['C']['atm60_oprice_test']   \n",
    "                df_coef_ts.loc[r, 'atm90_optice_test_C'] = dict_output[key]['C']['atm90_oprice_test']                 \n",
    "\n",
    "                df_coef_ts.loc[r, 'coef_P'] = dict_output[key]['P']['coef']\n",
    "                df_coef_ts.loc[r, 'std_P'] = dict_output[key]['P']['std']\n",
    "                df_coef_ts.loc[r, 'N_train_P'] = -dict_output[key]['P']['N_train']\n",
    "                df_coef_ts.loc[r, 'days_train_P'] = dict_output[key]['P']['days_train']\n",
    "                df_coef_ts.loc[r, 'N_test_P'] = dict_output[key]['P']['N_test']   \n",
    "                df_coef_ts.loc[r, 'atm30_vol_test_P'] = dict_output[key]['P']['atm30_vol_test']\n",
    "                df_coef_ts.loc[r, 'atm60_vol_test_P'] = dict_output[key]['P']['atm60_vol_test']\n",
    "                df_coef_ts.loc[r, 'atm90_vol_test_P'] = dict_output[key]['P']['atm90_vol_test']                \n",
    "                df_coef_ts.loc[r, 'atm30_optice_test_P'] = dict_output[key]['P']['atm30_oprice_test']\n",
    "                df_coef_ts.loc[r, 'atm60_optice_test_P'] = dict_output[key]['P']['atm60_oprice_test'] \n",
    "                df_coef_ts.loc[r, 'atm90_optice_test_P'] = dict_output[key]['P']['atm90_oprice_test']                 \n",
    "                r += 1\n",
    "\n",
    "            df_coef_ts = df_coef_ts.merge(temp[['Date', 'S0', 'AdjClosePrice', 'AdjClosePrice2']].drop_duplicates(), how = 'left', on = 'Date')\n",
    "            df_coef_ts.to_csv(output_path + 'coef/coef_' + str(i) + '_ts.csv', index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705b4d80-44d3-4665-8065-9b3c2d003660",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
